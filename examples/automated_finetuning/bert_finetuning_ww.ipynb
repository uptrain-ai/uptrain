{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6dfee5c5-323f-4774-b498-352db849e2b4",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  <a href=\"https://uptrain.ai\">\n",
    "    <img width=\"300\" src=\"https://user-images.githubusercontent.com/108270398/214240695-4f958b76-c993-4ddd-8de6-8668f4d0da84.png\" alt=\"uptrain\">\n",
    "  </a>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4003d261-596f-48fb-bd1e-e988a7029655",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Automated LLM Finetuning with UpTrain</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf39670a-5863-41ce-a41b-78cfc305486f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers weightwatcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8041ded-5129-4875-83b1-a1bf08dd0eff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch is available but CUDA is not. Defaulting to SciPy for SVD\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from transformers import BertTokenizer, BertForSequenceClassification, BertPreTrainedModel\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Optional, Tuple, Union\n",
    "\n",
    "from tqdm import trange\n",
    "import random\n",
    "import weightwatcher as ww\n",
    "import uptrain\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baf32abf-8164-468b-82ca-4a81b5576539",
   "metadata": {},
   "source": [
    "#### Download the SPAM collection Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dabb361-b866-4a70-851a-f9fcb902c06e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !wget 'https://archive.ics.uci.edu/ml/machine-learning-databases/00228/smsspamcollection.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c83b0b93-646b-4646-9575-dd1484cc7a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !unzip -o smsspamcollection.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "272f2e3a-6268-4727-8a17-de932c203ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                    Ok lar... Joking wif u oni...\\n\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path = './SMSSpamCollection'\n",
    "df = pd.DataFrame({'label':int(), 'text':str()}, index = [])\n",
    "with open(file_path) as f:\n",
    "    for line in f.readlines():\n",
    "        split = line.split('\\t')\n",
    "        df = df.append({'label': 1 if split[0] == 'spam' else 0,\n",
    "                    'text': split[1]},\n",
    "                    ignore_index = True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0fa75ab-37b6-4fce-b664-cd40af43ef5b",
   "metadata": {},
   "source": [
    "#### Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "059b8d43-d39e-4f90-b8e9-aafe4d32e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(input_text, tokenizer):\n",
    "    '''\n",
    "    Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
    "    - input_ids: list of token ids\n",
    "    - token_type_ids: list of token type ids\n",
    "    - attention_mask: list of indices (0,1) specifying which tokens should considered \n",
    "    by the model (return_attention_mask = True).\n",
    "    '''\n",
    "    return tokenizer.encode_plus(\n",
    "                        input_text,\n",
    "                        add_special_tokens = True,\n",
    "                        max_length = 32,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,\n",
    "                        return_tensors = 'pt'\n",
    "                   )\n",
    "\n",
    "def get_train_val_dataloader(df, train_idx, val_idx, fraction=1):\n",
    "    text = df.text.values\n",
    "    labels = df.label.values\n",
    "    truncate_dataset = False\n",
    "\n",
    "    if truncate_dataset:\n",
    "        text = text[0:int(len(text) * fraction)]\n",
    "        labels = labels[0:int(len(text) * fraction)]\n",
    "\n",
    "    tokenizer = BertTokenizer.from_pretrained(\n",
    "      'bert-base-uncased',\n",
    "      do_lower_case = True\n",
    "      )\n",
    "    token_id = []\n",
    "    attention_masks = []\n",
    "\n",
    "    for sample in text:\n",
    "        encoding_dict = preprocessing(sample, tokenizer)\n",
    "        token_id.append(encoding_dict['input_ids']) \n",
    "        attention_masks.append(encoding_dict['attention_mask'])\n",
    "\n",
    "\n",
    "    token_id = torch.cat(token_id, dim = 0)\n",
    "    attention_masks = torch.cat(attention_masks, dim = 0)\n",
    "    labels = torch.tensor(labels)\n",
    "\n",
    "    val_ratio = 0.2\n",
    "    batch_size = 16\n",
    "    # train_idx, val_idx = train_test_split(\n",
    "    #     np.arange(len(labels)),\n",
    "    #     test_size = val_ratio,\n",
    "    #     shuffle = True,\n",
    "    #     stratify = labels)\n",
    "\n",
    "    train_idx = train_idx[0:int(len(text) * fraction * (1 - val_ratio) )]\n",
    "\n",
    "    train_set = TensorDataset(token_id[train_idx], \n",
    "                            attention_masks[train_idx], \n",
    "                            labels[train_idx])\n",
    "\n",
    "    val_set = TensorDataset(token_id[val_idx], \n",
    "                          attention_masks[val_idx], \n",
    "                          labels[val_idx])\n",
    "\n",
    "    train_dataloader = DataLoader(\n",
    "              train_set,\n",
    "              sampler = RandomSampler(train_set),\n",
    "              batch_size = batch_size\n",
    "          )\n",
    "\n",
    "    validation_dataloader = DataLoader(\n",
    "              val_set,\n",
    "              sampler = SequentialSampler(val_set),\n",
    "              batch_size = batch_size\n",
    "          )\n",
    "    return train_dataloader, validation_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e2a54af-a533-44d0-8043-03dbdcc3f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import BertModel\n",
    "from torch.nn import BCEWithLogitsLoss, CrossEntropyLoss, MSELoss\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "473e7768-09e5-42e9-bef6-e5d312a98059",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertForSequenceClassificationWithIntermediateLayer(BertPreTrainedModel):\n",
    "  '''\n",
    "  Extends the BertForSequenceClassification class to return the logits of the intermediate layer.\n",
    "  '''\n",
    "  def __init__(self, config):\n",
    "    super().__init__(config)\n",
    "    # import pdb; pdb.set_trace()\n",
    "    self.num_labels = config.num_labels\n",
    "    self.config = config\n",
    "\n",
    "    self.bert = BertModel(config)\n",
    "    classifier_dropout = (\n",
    "        config.classifier_dropout if config.classifier_dropout is not None else config.hidden_dropout_prob\n",
    "    )\n",
    "    self.dropout = nn.Dropout(classifier_dropout)\n",
    "    self.post_bert = nn.Linear(config.hidden_size, config.hidden_size)\n",
    "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "    self.relu = nn.ReLU()\n",
    "    # Initialize weights and apply final processing\n",
    "    self.post_init()\n",
    "\n",
    "  def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], SequenceClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\n",
    "            Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\n",
    "            config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\n",
    "            `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        pooled_output = outputs[1]\n",
    "\n",
    "        pooled_output = self.dropout(pooled_output)\n",
    "        intermediate_output = self.post_bert(pooled_output)\n",
    "        intermediate_output = self.relu(intermediate_output)\n",
    "        intermediate_output = self.dropout(intermediate_output)\n",
    "        logits = self.classifier(intermediate_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            if self.config.problem_type is None:\n",
    "                if self.num_labels == 1:\n",
    "                    self.config.problem_type = \"regression\"\n",
    "                elif self.num_labels > 1 and (labels.dtype == torch.long or labels.dtype == torch.int):\n",
    "                    self.config.problem_type = \"single_label_classification\"\n",
    "                else:\n",
    "                    self.config.problem_type = \"multi_label_classification\"\n",
    "\n",
    "            if self.config.problem_type == \"regression\":\n",
    "                loss_fct = MSELoss()\n",
    "                if self.num_labels == 1:\n",
    "                    loss = loss_fct(logits.squeeze(), labels.squeeze())\n",
    "                else:\n",
    "                    loss = loss_fct(logits, labels)\n",
    "            elif self.config.problem_type == \"single_label_classification\":\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "                loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            elif self.config.problem_type == \"multi_label_classification\":\n",
    "                loss_fct = BCEWithLogitsLoss()\n",
    "                loss = loss_fct(logits, labels)\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return SequenceClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f092c6-7566-4b36-aa64-49ce6fc9e1b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassificationWithIntermediateLayer: ['cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassificationWithIntermediateLayer from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassificationWithIntermediateLayer from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassificationWithIntermediateLayer were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['post_bert.bias', 'classifier.bias', 'classifier.weight', 'post_bert.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassificationWithIntermediateLayer.from_pretrained('bert-base-uncased', \n",
    "                                                                           num_labels = 2, \n",
    "                                                                           output_attentions = False, \n",
    "                                                                           output_hidden_states = False)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "if device == 'cpu':\n",
    "    # set device to mps if available (for mac)\n",
    "    device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "device = torch.device(device)\n",
    "model.to(device)\n",
    "optimizer = torch.optim.AdamW(\n",
    "                        model.parameters(), \n",
    "                          lr = 5e-5,\n",
    "                          eps = 1e-08\n",
    "                          )\n",
    "optimizer_type = 'AdamW'\n",
    "optimizer_base_lr = 2e-5\n",
    "\n",
    "val_ratio = 0.2\n",
    "labels = df.label.values\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(labels)),\n",
    "    test_size = val_ratio,\n",
    "    shuffle = True,\n",
    "    stratify = labels)\n",
    "train_dataloader, val_dataloader = get_train_val_dataloader(df,train_idx, val_idx, fraction=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "64cc28a8-c63e-42cb-8f23-7db2842844f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data size:  279\n",
      "Validation data size:  70\n"
     ]
    }
   ],
   "source": [
    "print(\"Training data size: \" , len(train_dataloader))\n",
    "print(\"Validation data size: \" , len(val_dataloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282af604-599c-4cbd-88a0-f93570489430",
   "metadata": {},
   "source": [
    "### Define the UpTrain Config "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0636bed0-5293-4b50-8aff-deb1d3af6237",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"checks\": [\n",
    "    {'type': uptrain.Statistic.FINETUNE,\n",
    "    'optimizer': optimizer,\n",
    "    'dataloader': train_dataloader,\n",
    "    'layers': [230],\n",
    "    'customLR': True,\n",
    "    'base_lr': 2e-5,\n",
    "    }\n",
    "    ],\n",
    "    \"logging_args\": {\"st_logging\": True,\n",
    "                    \"log_data\": False,\n",
    "                    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2296328f-5645-4aba-aa9c-5d9ae291a40c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data\n",
      "Deleting the folder:  uptrain_logs\n"
     ]
    }
   ],
   "source": [
    "framework = uptrain.Framework(cfg_dict=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee294d0-6ce6-4e4d-983e-12dc7f0ee427",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://192.168.6.64:8501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "framework.log(inputs={'model': [model]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376d04c4-f573-406c-a5d4-3074c5c73b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "val_accuracy = []\n",
    "val_precision = []\n",
    "val_recall = []\n",
    "val_specificity = []\n",
    "\n",
    "nb_val_examples, nb_val_steps = 0, 0\n",
    "\n",
    "for batch in val_dataloader:\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    with torch.no_grad():\n",
    "        # Forward pass\n",
    "        eval_output = model(b_input_ids.to(device), \n",
    "                            token_type_ids = None, \n",
    "                            attention_mask = b_input_mask.to(device),\n",
    "                                labels = b_labels.to(device)\n",
    "                            )\n",
    "    val_loss += eval_output.loss.item()\n",
    "    nb_val_examples += b_input_ids.size(0)\n",
    "    nb_val_steps += 1\n",
    "\n",
    "    logits = eval_output.logits.detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    # Calculate validation metrics\n",
    "    b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
    "    val_accuracy.append(b_accuracy)\n",
    "    # Update precision only when (tp + fp) !=0; ignore nan\n",
    "    if b_precision != 'nan': val_precision.append(b_precision)\n",
    "    # Update recall only when (tp + fn) !=0; ignore nan\n",
    "    if b_recall != 'nan': val_recall.append(b_recall)\n",
    "    # Update specificity only when (tn + fp) !=0; ignore nan\n",
    "    if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
    "\n",
    "print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
    "print('\\t - Validation loss: {:.4f}'.format(val_loss / nb_val_steps))\n",
    "print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
    "print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) \n",
    "      if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
    "print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) \n",
    "      if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
    "print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) \n",
    "      if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
