{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62ae031-5e14-4675-a48e-4f5e371394aa",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  <a href=\"https://uptrain.ai\">\n",
    "    <img width=\"300\" src=\"https://user-images.githubusercontent.com/108270398/214240695-4f958b76-c993-4ddd-8de6-8668f4d0da84.png\" alt=\"uptrain\">\n",
    "  </a>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d8c0e-d99c-40dc-a06f-9f9f70aa81a0",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Performance Monitoring on a Binary Classification Model</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f184c-e1a6-4f5e-be14-f959973a1a83",
   "metadata": {},
   "source": [
    "**Dataset and ML model**: In this example, we train a binary classifier on a popular network traffic dataset called the [NSL-KDD dataset](https://www.unb.ca/cic/datasets/nsl.html) for cyber-attack classification using the [XGBoost classifier](https://xgboost.readthedocs.io/en/stable/). \n",
    "\n",
    "**Problem**: Once we train the cyber-attack classification model, it performs well initially, but later, the attackers catch up and change their manner of attacks, which causes our model predictions to go wrong. \n",
    "\n",
    "**Solution**: Use the UpTrain framework to indentify the drift in model predictions (aka concept drift)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ff2ab59-8688-4431-a6b6-e00b5b22dfba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a18cd-d4d1-40cd-a996-faf41c1d2f2c",
   "metadata": {},
   "source": [
    "### Install required packages for this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fcf6586-639e-4b45-8dfd-671f724c766f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4bb6b22b-52f4-49df-9745-35dd53dccfbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import uptrain\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da3324-93a3-459e-9bb4-c73ee4132fe4",
   "metadata": {},
   "source": [
    "First, we download the preprocessed NSL-KDD dataset (if not already exists). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ff84103b-5354-4d35-b3df-70ba8f58cbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file exists. Skipping download.\n"
     ]
    }
   ],
   "source": [
    "data_file = \"NSL_KDD_binary.csv\"\n",
    "remote_url = \"https://oodles-dev-training-data.s3.amazonaws.com/NSL_KDD_binary.csv\"\n",
    "if not os.path.exists(data_file):\n",
    "    try:\n",
    "        # Most Linux distributions have Wget installed by default.\n",
    "        # Below command is to install wget for MacOS\n",
    "        wget_installed_ok = subprocess.call(\"brew install wget\", shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "        print(\"Successfully installed wget\")\n",
    "    except:\n",
    "        dummy = 1\n",
    "    try:\n",
    "        if not os.path.exists(\"data.zip\"):\n",
    "            file_downloaded_ok = subprocess.call(\"wget \" + remote_url, shell=True, stdout=subprocess.DEVNULL, stderr=subprocess.STDOUT)\n",
    "            print(\"Data downloaded\")\n",
    "    except:\n",
    "        print(e)\n",
    "        print(\"Could not load training data\")\n",
    "        print(\"Please follow following steps to manually download data\")\n",
    "        print(\"Step 1: Open in browser: https://oodles-dev-training-data.s3.amazonaws.com/NSL_KDD_binary.csv\")\n",
    "        print(\"Step 2: Download and move the file to example location (i.e. uptrain/examples/2_cyber_attack_classification/\")\n",
    "else:\n",
    "    print(\"Data file exists. Skipping download.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89c129-f5e1-4644-9d37-f58398970260",
   "metadata": {},
   "source": [
    "### Read the training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cee0e008-c9b3-460a-990e-2716ea5483b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "X = df.iloc[:, :-1].values\n",
    "y = df.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732b268-f547-433d-96d5-0ca0a33932d5",
   "metadata": {},
   "source": [
    "### Divide the data into training and test sets\n",
    "We use first 10% of the data to train and 90% of the data to evaluate the model in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9cffb270-0cb5-4f84-83ea-e8f195dae0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size = 0.1, \n",
    "                                                    test_size = 0.9, \n",
    "                                                    random_state = 0,\n",
    "                                                    shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee01c1-6cd7-41ab-b060-3d0bcff1c51d",
   "metadata": {},
   "source": [
    "### Step 1: Train our XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bad7ee0b-7318-4a2f-a681-81bac98547f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost classifier with training data\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_train)\n",
    "print(\"Training accuracy: \" + str(100*accuracy_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5fe45-e1df-4026-8061-5ec5eeef5ac5",
   "metadata": {},
   "source": [
    "Woah! ðŸ˜²ðŸ”¥ The training accuracy is 100%. Let's see how long the model lasts in production. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88f8514e-1d1f-4d15-adec-a3380f6f9a78",
   "metadata": {},
   "source": [
    "## Identifying Concept Drift\n",
    "\n",
    "In this example, we implement two methods to identify concep drift:\n",
    "1. Use the popular concept drift detectection algorithm for binary tasks called the [Drift Detection Method (DDM)](https://riverml.xyz/dev/api/drift/DDM/). DDM is implemented as a part of the UpTrain package.\n",
    "2. A custom drift metric that is defined by the user below. Specifically, the user wants to monitor the difference between accuracy of the model on the first 200 predictions and the most recent 200 predictions. This way, they can quickly identify if there was a sudden degradation in the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c7b1d-a489-48be-9886-84421053a3fa",
   "metadata": {},
   "source": [
    "### Step 2: Defining a Custom Monitor on the initial and most recent performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1322464e-0917-4f68-aa4c-214a9b6fa7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Defining a custom drift metric where\n",
    "the user just want to check if accuracy \n",
    "drops beyond a threshold.\n",
    "\"\"\"\n",
    "\n",
    "def custom_initialize_func(self):\n",
    "    self.initial_acc = None       \n",
    "    self.acc_arr = []\n",
    "    self.count = 0       \n",
    "    self.thres = 0.02\n",
    "    self.window_size = 200\n",
    "    self.is_drift_detected = False\n",
    "\n",
    "def custom_check_func(self, inputs, outputs, gts=None, extra_args={}):\n",
    "    batch_size = len(extra_args[\"id\"])\n",
    "    self.count += batch_size\n",
    "    self.acc_arr.extend(list(np.equal(gts, outputs)))\n",
    "    \n",
    "    # Calculate initial performance of the model on first 200 points\n",
    "    if (self.count >= self.window_size) and (self.initial_acc is None):\n",
    "        self.initial_acc = sum(self.acc_arr[0:self.window_size])/self.window_size\n",
    "        \n",
    "    # Calculate the most recent accuracy and log it to dashboard.\n",
    "    if (self.initial_acc is not None):\n",
    "        for i in range(self.count - batch_size, self.count, self.window_size):\n",
    "            \n",
    "            # Calculate the most recent accuracy\n",
    "            recent_acc = sum(self.acc_arr[i:i+self.window_size])/self.window_size\n",
    "            \n",
    "            # Logging to UpTrain dashboard\n",
    "            self.log_handler.add_scalars('custom_metrics', {\n",
    "                    'initial_acc': self.initial_acc,\n",
    "                    'recent_acc': recent_acc,\n",
    "                }, i, self.dashboard_name)\n",
    "            \n",
    "            # Print a message when recent model performance goes down \n",
    "            if (self.initial_acc - recent_acc > self.thres) and (not self.is_drift_detected):\n",
    "                    print(\"Concept drift detected with custom metric at time: \", i)\n",
    "                    self.is_drift_detected = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed898b8-753f-47ed-8db1-0331147c05d4",
   "metadata": {},
   "source": [
    "### Step 3: Define the list of checks to perform on model\n",
    "Here, we have two checks: concept drfit check with DDM algorithm and the customized check from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "93a3edbc-b1e4-47d3-b620-cadc69ed1004",
   "metadata": {},
   "outputs": [],
   "source": [
    "checks = [\n",
    "    {\n",
    "    'type': uptrain.Anomaly.CONCEPT_DRIFT,\n",
    "    'algorithm': uptrain.DataDriftAlgo.DDM,\n",
    "    'warn_thres': 2,\n",
    "    'alarm_thres': 3,\n",
    "    },\n",
    "    {\n",
    "    'type': uptrain.Anomaly.CUSTOM_MONITOR,\n",
    "    'initialize_func': custom_initialize_func,\n",
    "    'check_func': custom_check_func,\n",
    "    'need_gt': True,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c38076d-babb-46f8-b853-fb9796faae4a",
   "metadata": {},
   "source": [
    "### Step 4: Define config and initialize the UpTrain framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1adaa6a1-9e00-4365-a886-7f1785f04f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data\n",
      "Deleting the folder:  uptrain_logs\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    # Checks to identify concept drift\n",
    "    \"checks\": checks,\n",
    "    \n",
    "    # Folder that stores data logged by UpTrain\n",
    "    \"retraining_folder\": 'uptrain_smart_data',\n",
    "    \n",
    "    # Enable streamlit logging\n",
    "    # Note: Requires streamlit to be installed \n",
    "    \"st_logging\": True,\n",
    "}\n",
    "\n",
    "# Initialize the UpTrain framework\n",
    "framework = uptrain.Framework(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8964a1d-801e-4c25-ba00-0920b2dc12d0",
   "metadata": {},
   "source": [
    "### Step 5: Deploy the model in production and wait for alerts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec793e01-fe2a-4ee0-b258-968936853950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://192.168.6.64:8501\n",
      "\n",
      "Drift detected with DDM at time:  111298\n",
      "Concept drift detected with custom metric at time:  111000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 10000\n",
    "for i in range(int(len(X_test)/batch_size)):\n",
    "    \n",
    "    # Do model prediction\n",
    "    inputs = {'data': {\"feats\": X_test[i*batch_size:(i+1)*batch_size]}}\n",
    "    preds = classifier.predict(inputs['data'][\"feats\"])\n",
    "    \n",
    "    # Log model inputs and outputs to monitor concept drift\n",
    "    ids = framework.log(inputs=inputs, outputs=preds)\n",
    "    \n",
    "    # Attach ground truth to corresponding predictions \n",
    "    # in UpTrain framewrok and identify concept drift\n",
    "    ground_truth = y_test[i*batch_size:(i+1)*batch_size] \n",
    "    framework.log(identifiers=ids, gts = ground_truth)\n",
    "    \n",
    "    # Pausing between batches to monitor progress in the dashboard\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46d07f60-a4b8-4fac-bb11-175c0c57634f",
   "metadata": {},
   "source": [
    "As can be noted from above, our two drift monitors predict a drift around the timestamp of 111k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98149437-3f72-4db7-86ce-ce93d8815d51",
   "metadata": {},
   "source": [
    "### Verification of drifts with the UpTrain dashboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c998ab-9381-4d51-a52d-9853828f7e70",
   "metadata": {},
   "source": [
    "The UpTrain framework automatically logs important metrics such as accuracy for the user to observe the performance of their models. The dashboard is currently integrated with **streamlit** and is launched automatically if *st_logging* is enables in streamlit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02af9455-8c89-4ac6-9042-3b9fd5b9c439",
   "metadata": {},
   "source": [
    "### Accuracy versus num_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf515cd-591e-4a4a-911b-b4f52a1aa68c",
   "metadata": {},
   "source": [
    "The following is a screenshot of average accuracy versus time from the dashboard. We can observe a data drift around the timestamp of 111k, which is also predicted by our drift monitors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac2a23-d962-4a4a-ab08-e5da0d5bfaaf",
   "metadata": {},
   "source": [
    "<img width=\"629\" alt=\"concept_drift_avg_acc\" src=\"https://user-images.githubusercontent.com/5287871/216795937-7e3e0609-6053-4256-956d-c07de3b7d73e.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "185c9d3b-e6a6-4ced-9a8d-3e0df6107639",
   "metadata": {},
   "source": [
    "### Custom Monitor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36469265-9f5b-4cad-9a2e-181defa764f4",
   "metadata": {},
   "source": [
    "Finally, the users can also plot the customized metrics we defined earlier, which in this case were the initial accuracy of the model and the most recent accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3b50f54-ebdd-4f03-944c-2b6e5bd5318c",
   "metadata": {},
   "source": [
    "<img width=\"624\" alt=\"concept_drift_custom\" src=\"https://user-images.githubusercontent.com/5287871/216795956-a35bcd9f-8b60-439d-9ea2-8e19854390bb.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d789ada2-8d07-4713-9572-2ca2a41c3a46",
   "metadata": {},
   "source": [
    "Observe how the most **recent accuracy** of the model is **far lower** than the **initial accuracy**, implying that the attackers have learned to fool the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "9545c455b197f2a904e8a44b25c9f43f9436523cf18f2465849be78ad0c6016f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
