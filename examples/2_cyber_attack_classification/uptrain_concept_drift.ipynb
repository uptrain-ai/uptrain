{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e62ae031-5e14-4675-a48e-4f5e371394aa",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  <a href=\"https://uptrain.ai\">\n",
    "    <img width=\"300\" src=\"https://user-images.githubusercontent.com/108270398/214240695-4f958b76-c993-4ddd-8de6-8668f4d0da84.png\" alt=\"uptrain\">\n",
    "  </a>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d8c0e-d99c-40dc-a06f-9f9f70aa81a0",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Performance Monitoring: Cyber-Attack Detection</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "703f184c-e1a6-4f5e-be14-f959973a1a83",
   "metadata": {},
   "source": [
    "**Overview**: In this example, we see how to use UpTrain to monitor performance of a cyber-attack classification task. For the same, we will be training a binary classifier on a popular network traffic dataset called the [NSL-KDD dataset](https://www.unb.ca/cic/datasets/nsl.html) for cyber-attack classification using the [XGBoost classifier](https://xgboost.readthedocs.io/en/stable/). \n",
    "\n",
    "**Dataset**: The NSL-KDD dataset includes a variety of network attack types, including denial-of-service (DoS) attacks, unauthorized access (U2R) attacks, and probe attacks. The dataset contains a total of around 25,000 instances and 41 different features that describe the behavior of network connections, such as the number of failed login attempts and the size of packets transmitted.\n",
    "\n",
    "**Why is monitoring needed**: Once our cyber-attack classification model has been trained, it may initially perform well in detecting malicious activity. However, over time, attackers may adapt their tactics and evolve their methods, leading to a mismatch between the type of attacks seen during training and those seen in production. This can result in decreased accuracy in our model's predictions.\n",
    "\n",
    "**Solution**: We will be using UpTrain framework which provides an easy-to-configure way to log model predictions and attach ground-truth to monitor model's performance. We are using drift detection methon on top on model performance to raise alerts in case of any dip in model's accuracy, commonly called **Concept Drift.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899a18cd-d4d1-40cd-a996-faf41c1d2f2c",
   "metadata": {},
   "source": [
    "### Install required packages for this example [XGBoost]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fcf6586-639e-4b45-8dfd-671f724c766f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (1.7.3)\n",
      "Requirement already satisfied: streamlit in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (1.18.1)\n",
      "Requirement already satisfied: scipy in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages/scipy-1.10.0-py3.10-macosx-11.1-arm64.egg (from xgboost) (1.10.0)\n",
      "Requirement already satisfied: numpy in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages/numpy-1.23.5-py3.10-macosx-11.1-arm64.egg (from xgboost) (1.23.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.12 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (3.20.3)\n",
      "Requirement already satisfied: altair>=3.2.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (4.2.2)\n",
      "Requirement already satisfied: toml in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (0.10.2)\n",
      "Requirement already satisfied: pympler>=0.9 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (1.0.1)\n",
      "Requirement already satisfied: validators>=0.2 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (0.20.0)\n",
      "Requirement already satisfied: cachetools>=4.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (5.3.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (3.1.30)\n",
      "Requirement already satisfied: packaging>=14.1 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (23.0)\n",
      "Requirement already satisfied: tornado>=6.0.3 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (6.2)\n",
      "Requirement already satisfied: pandas>=0.25 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages/pandas-1.5.3-py3.10-macosx-11.1-arm64.egg (from streamlit) (1.5.3)\n",
      "Requirement already satisfied: pydeck>=0.1.dev5 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (0.8.0)\n",
      "Requirement already satisfied: requests>=2.4 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (2.28.2)\n",
      "Requirement already satisfied: python-dateutil in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages/python_dateutil-2.8.2-py3.10.egg (from streamlit) (2.8.2)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (13.3.1)\n",
      "Requirement already satisfied: click>=7.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (8.1.3)\n",
      "Requirement already satisfied: pyarrow>=4.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (11.0.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (9.4.0)\n",
      "Requirement already satisfied: blinker>=1.0.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (1.5)\n",
      "Requirement already satisfied: typing-extensions>=3.10.0.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages/typing_extensions-4.4.0-py3.10.egg (from streamlit) (4.4.0)\n",
      "Requirement already satisfied: semver in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (2.13.0)\n",
      "Requirement already satisfied: importlib-metadata>=1.4 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (6.0.0)\n",
      "Requirement already satisfied: tzlocal>=1.1 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from streamlit) (4.2)\n",
      "Requirement already satisfied: entrypoints in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from altair>=3.2.0->streamlit) (0.4)\n",
      "Requirement already satisfied: toolz in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from altair>=3.2.0->streamlit) (0.12.0)\n",
      "Requirement already satisfied: jinja2 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from altair>=3.2.0->streamlit) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from altair>=3.2.0->streamlit) (4.17.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from gitpython!=3.1.19->streamlit) (4.0.10)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from importlib-metadata>=1.4->streamlit) (3.13.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages/pytz-2022.7.1-py3.10.egg (from pandas>=0.25->streamlit) (2022.7.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages/six-1.16.0-py3.10.egg (from python-dateutil->streamlit) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from requests>=2.4->streamlit) (3.0.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from requests>=2.4->streamlit) (1.26.14)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from requests>=2.4->streamlit) (2022.12.7)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from requests>=2.4->streamlit) (3.4)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.1.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from rich>=10.11.0->streamlit) (2.1.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.14.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from rich>=10.11.0->streamlit) (2.14.0)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from tzlocal>=1.1->streamlit) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from validators>=0.2->streamlit) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19->streamlit) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from jinja2->altair>=3.2.0->streamlit) (2.1.2)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (22.2.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from jsonschema>=3.0->altair>=3.2.0->streamlit) (0.19.3)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.1.0->rich>=10.11.0->streamlit) (0.1.2)\n",
      "Requirement already satisfied: tzdata in /Users/sourabhagrawal/miniconda3/envs/prod_dev/lib/python3.10/site-packages (from pytz-deprecation-shim->tzlocal>=1.1->streamlit) (2022.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost streamlit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221b823c-b321-4a81-be40-4935a49d8a4c",
   "metadata": {},
   "source": [
    "#### Let's first import all the required packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bb6b22b-52f4-49df-9745-35dd53dccfbf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import uptrain\n",
    "import time\n",
    "import numpy as np\n",
    "import yaml \n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from helper_funcs import download_dataset, pretty\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67da3324-93a3-459e-9bb4-c73ee4132fe4",
   "metadata": {},
   "source": [
    "## Step 1: Let's download and prepare the NSL-KDD dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff84103b-5354-4d35-b3df-70ba8f58cbd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data file exists. Skipping download.\n",
      "NSL_KDD_binary.csv dataset prepared successfully!\n"
     ]
    }
   ],
   "source": [
    "data_file = \"NSL_KDD_binary.csv\"\n",
    "download_dataset(data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db89c129-f5e1-4644-9d37-f58398970260",
   "metadata": {},
   "source": [
    "#### Let's read the data and see how it looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cee0e008-c9b3-460a-990e-2716ea5483b2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels for first few rows:\n",
      "[0, 0, 1, 0, 0] \n",
      "\n",
      "Input features for first few rows:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>duration</th>\n",
       "      <th>protocol_type</th>\n",
       "      <th>service</th>\n",
       "      <th>flag</th>\n",
       "      <th>src_bytes</th>\n",
       "      <th>dst_bytes</th>\n",
       "      <th>land</th>\n",
       "      <th>wrong_fragment</th>\n",
       "      <th>urgent</th>\n",
       "      <th>hot</th>\n",
       "      <th>...</th>\n",
       "      <th>dst_host_count</th>\n",
       "      <th>dst_host_srv_count</th>\n",
       "      <th>dst_host_same_srv_rate</th>\n",
       "      <th>dst_host_diff_srv_rate</th>\n",
       "      <th>dst_host_same_src_port_rate</th>\n",
       "      <th>dst_host_srv_diff_host_rate</th>\n",
       "      <th>dst_host_serror_rate</th>\n",
       "      <th>dst_host_srv_serror_rate</th>\n",
       "      <th>dst_host_rerror_rate</th>\n",
       "      <th>dst_host_srv_rerror_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>9</td>\n",
       "      <td>491</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>150</td>\n",
       "      <td>25</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>49</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>26</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>232</td>\n",
       "      <td>8153</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>30</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>9</td>\n",
       "      <td>199</td>\n",
       "      <td>420</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>255</td>\n",
       "      <td>255</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   duration  protocol_type  service  flag  src_bytes  dst_bytes  land  \\\n",
       "0         0              1       20     9        491          0     0   \n",
       "1         0              2       44     9        146          0     0   \n",
       "2         0              1       49     5          0          0     0   \n",
       "3         0              1       24     9        232       8153     0   \n",
       "4         0              1       24     9        199        420     0   \n",
       "\n",
       "   wrong_fragment  urgent  hot  ...  dst_host_count  dst_host_srv_count  \\\n",
       "0               0       0    0  ...             150                  25   \n",
       "1               0       0    0  ...             255                   1   \n",
       "2               0       0    0  ...             255                  26   \n",
       "3               0       0    0  ...              30                 255   \n",
       "4               0       0    0  ...             255                 255   \n",
       "\n",
       "   dst_host_same_srv_rate  dst_host_diff_srv_rate  \\\n",
       "0                    0.17                    0.03   \n",
       "1                    0.00                    0.60   \n",
       "2                    0.10                    0.05   \n",
       "3                    1.00                    0.00   \n",
       "4                    1.00                    0.00   \n",
       "\n",
       "   dst_host_same_src_port_rate  dst_host_srv_diff_host_rate  \\\n",
       "0                         0.17                         0.00   \n",
       "1                         0.88                         0.00   \n",
       "2                         0.00                         0.00   \n",
       "3                         0.03                         0.04   \n",
       "4                         0.00                         0.00   \n",
       "\n",
       "   dst_host_serror_rate  dst_host_srv_serror_rate  dst_host_rerror_rate  \\\n",
       "0                  0.00                      0.00                  0.05   \n",
       "1                  0.00                      0.00                  0.00   \n",
       "2                  1.00                      1.00                  0.00   \n",
       "3                  0.03                      0.01                  0.00   \n",
       "4                  0.00                      0.00                  0.00   \n",
       "\n",
       "   dst_host_srv_rerror_rate  \n",
       "0                      0.00  \n",
       "1                      0.00  \n",
       "2                      0.00  \n",
       "3                      0.01  \n",
       "4                      0.00  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(data_file)\n",
    "print(\"Labels for first few rows:\")\n",
    "print(list(df['label'].head()), \"\\n\")\n",
    "print(\"Input features for first few rows:\")\n",
    "df.drop(\"label\", axis=1).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6732b268-f547-433d-96d5-0ca0a33932d5",
   "metadata": {},
   "source": [
    "#### Divide the data into training and test sets\n",
    "We use first 10% of the data to train and 90% of the data to evaluate the model in production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9cffb270-0cb5-4f84-83ea-e8f195dae0fc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Training samples:  14851,  Num Testing samples:  133666\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df.iloc[:, :-1].values, df.iloc[:, -1].values,\n",
    "                                                    test_size = 0.9, \n",
    "                                                    random_state = 0,\n",
    "                                                    shuffle=False)\n",
    "\n",
    "print(\"Num Training samples: \", str(len(X_train)) + \",\", \" Num Testing samples: \", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ee01c1-6cd7-41ab-b060-3d0bcff1c51d",
   "metadata": {},
   "source": [
    "## Step 2: Train our XGBoost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bad7ee0b-7318-4a2f-a681-81bac98547f5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy: 100.0\n"
     ]
    }
   ],
   "source": [
    "# Train the XGBoost classifier with training data\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_pred = classifier.predict(X_train)\n",
    "print(\"Training accuracy: \" + str(100*accuracy_score(y_train, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c5fe45-e1df-4026-8061-5ec5eeef5ac5",
   "metadata": {},
   "source": [
    "Woah! ðŸ˜²ðŸ”¥ The training accuracy is 100%. Let's see how long the model lasts in production. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db5c7b1d-a489-48be-9886-84421053a3fa",
   "metadata": {},
   "source": [
    "## Step 3: Monitoring model performance using UpTrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "09bf8897-5807-4899-bf48-4dfbdfcca7fb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- checks:\n",
      "\t- type:\n",
      "\t\tAnomaly.CONCEPT_DRIFT\n",
      "\t- algorithm:\n",
      "\t\tDataDriftAlgo.DDM\n",
      "- retraining_folder:\n",
      "\tuptrain_smart_data\n",
      "- st_logging:\n",
      "\tTrue\n"
     ]
    }
   ],
   "source": [
    "cfg = {\n",
    "    # Checks to identify concept drift\n",
    "    \"checks\": [{\n",
    "        'type': uptrain.Anomaly.CONCEPT_DRIFT,\n",
    "        'algorithm': uptrain.DataDriftAlgo.DDM\n",
    "    }],\n",
    "    \n",
    "    # Folder that stores the drifted data-points identified by UpTrain\n",
    "    \"retraining_folder\": 'uptrain_smart_data',\n",
    "    \n",
    "    # Enable streamlit logging to visualize model's performance\n",
    "    \"st_logging\": True,\n",
    "}\n",
    "pretty(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "474b25b9-c0cd-4cfb-bb34-f2e5a0eb5069",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data\n",
      "Deleting the folder:  uptrain_logs\n",
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://192.168.6.92:8501\n",
      "\n",
      "  For better performance, install the Watchdog module:\n",
      "\n",
      "  $ xcode-select --install\n",
      "  $ pip install watchdog\n",
      "            \n",
      "Drift detected with DDM at time: 111298!!!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the UpTrain framework\n",
    "framework = uptrain.Framework(cfg)\n",
    "\n",
    "batch_size = 10000\n",
    "for i in range(int(len(X_test)/batch_size)):\n",
    "    \n",
    "    # Do model prediction\n",
    "    inputs = {'data': {\"feats\": X_test[i*batch_size:(i+1)*batch_size]}}\n",
    "    preds = classifier.predict(inputs['data'][\"feats\"])\n",
    "    \n",
    "    # Log model inputs and outputs to monitor concept drift\n",
    "    ids = framework.log(inputs=inputs, outputs=preds)\n",
    "    \n",
    "    # Attach ground truth to corresponding predictions \n",
    "    # in UpTrain framework and identify concept drift\n",
    "    ground_truth = y_test[i*batch_size:(i+1)*batch_size] \n",
    "    framework.log(identifiers=ids, gts=ground_truth)\n",
    "    \n",
    "    # Pausing between batches to monitor progress in the dashboard\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ded14442-b8d3-4aef-9848-b4e1af3796c4",
   "metadata": {
    "tags": []
   },
   "source": [
    "As can be noted from the dashboard, we start seeing a sharp dip in model's accuracy around the timestamp of 111k."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42079eb-b549-4fe8-88dd-442ddd255271",
   "metadata": {},
   "source": [
    "<img width=\"629\" alt=\"concept_drift_avg_acc\" src=\"https://user-images.githubusercontent.com/5287871/216795937-7e3e0609-6053-4256-956d-c07de3b7d73e.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8284211-8a38-4a30-80eb-2afb5ad698ec",
   "metadata": {},
   "source": [
    "In the this example, we used a popular drift detection algorithm called the [Drift Detection Method (DDM)](https://riverml.xyz/0.11.1/api/drift/DDM/) which is already implemented as a part of the UpTrain package. However, as we see the model accuracy is dropping from 99.7% to 96.9% which is still a slow decline but not might raise many eyebrows. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0124e2a3-75f7-454e-93de-02525b70e14d",
   "metadata": {},
   "source": [
    "For better detection and understanding the severity of the issue, one might want to define a customized metric and monitor the models using them. Let's see how to do that in UpTrain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbe4b52-2880-411b-a1c5-432dad0bac69",
   "metadata": {},
   "source": [
    "## Step 4: Define a Custom Monitor in UpTrain (for better monitoring)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a788df-c12f-4aea-a5d7-62e6199d4eff",
   "metadata": {},
   "source": [
    "We now define a custom drift metric which monitors the difference between accuracy of the model on the first 200 predictions and the most recent 200 predictions. This way, they can quickly identify if there was a sudden degradation in the model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03243b43-67bb-4817-a9ce-0a75a3b686ae",
   "metadata": {},
   "source": [
    "Let's define our custom check and UpTrain config with check as \"Custom Monitor\" as below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1322464e-0917-4f68-aa4c-214a9b6fa7c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- checks:\n",
      "\t- type:\n",
      "\t\tAnomaly.CUSTOM_MONITOR\n",
      "\t- initialize_func:\n",
      "\t\t<function custom_initialize_func at 0x2884b0e50>\n",
      "\t- check_func:\n",
      "\t\t<function custom_check_func at 0x2884b13f0>\n",
      "\t- need_gt:\n",
      "\t\tTrue\n",
      "- retraining_folder:\n",
      "\tuptrain_smart_data\n",
      "- st_logging:\n",
      "\tTrue\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Defining a custom drift metric to check if accuracy drops beyond a threshold.\n",
    "\"\"\"\n",
    "\n",
    "def custom_initialize_func(self):\n",
    "    self.initial_acc = None       \n",
    "    self.acc_arr = []\n",
    "    self.count = 0       \n",
    "    self.thres = 0.02\n",
    "    self.window_size = 200\n",
    "    self.is_drift_detected = False\n",
    "\n",
    "def custom_check_func(self, inputs, outputs, gts=None, extra_args={}):\n",
    "    batch_size = len(extra_args[\"id\"])\n",
    "    self.count += batch_size\n",
    "    self.acc_arr.extend(list(np.equal(gts, outputs)))\n",
    "    \n",
    "    # Calculate initial performance of the model on first 200 points\n",
    "    if (self.count >= self.window_size) and (self.initial_acc is None):\n",
    "        self.initial_acc = sum(self.acc_arr[0:self.window_size])/self.window_size\n",
    "        \n",
    "    # Calculate the most recent accuracy and log it to dashboard.\n",
    "    if (self.initial_acc is not None):\n",
    "        for i in range(self.count - batch_size, self.count, self.window_size):\n",
    "            \n",
    "            # Calculate the most recent accuracy\n",
    "            recent_acc = sum(self.acc_arr[i:i+self.window_size])/self.window_size\n",
    "            \n",
    "            # Logging to UpTrain dashboard\n",
    "            self.log_handler.add_scalars('custom_metrics', {\n",
    "                    'initial_acc': self.initial_acc,\n",
    "                    'recent_acc': recent_acc,\n",
    "                }, i, self.dashboard_name)\n",
    "            \n",
    "            # Send an alert when recent model performance goes down \n",
    "            if (self.initial_acc - recent_acc > self.thres) and (not self.is_drift_detected):\n",
    "                alert = f\"Concept drift detected with custom metric at time: {i}!!!\" \n",
    "                print(alert)\n",
    "                self.log_handler.add_alert(\n",
    "                    \"Model Performance Degradation Alert ðŸš¨\",\n",
    "                    alert,\n",
    "                    self.dashboard_name\n",
    "                )\n",
    "                self.is_drift_detected = True\n",
    "\n",
    "cfg = {\n",
    "    # Checks for our custom monitor\n",
    "    \"checks\": [{\n",
    "        'type': uptrain.Anomaly.CUSTOM_MONITOR,\n",
    "        'initialize_func': custom_initialize_func,\n",
    "        'check_func': custom_check_func,\n",
    "        'need_gt': True,\n",
    "    }],\n",
    "    \n",
    "    # Folder that stores the drifted data-points identified by UpTrain\n",
    "    \"retraining_folder\": 'uptrain_smart_data',\n",
    "    \n",
    "    # Enable streamlit logging to visualize model's performance\n",
    "    \"st_logging\": True,\n",
    "}\n",
    "pretty(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "63118254-37a2-4ec0-9a9d-16a4c3e376d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data\n",
      "Deleting the folder:  uptrain_logs\n",
      "Concept drift detected with custom metric at time: 111000!!!\n"
     ]
    }
   ],
   "source": [
    "# Initialize the UpTrain framework\n",
    "framework = uptrain.Framework(cfg)\n",
    "\n",
    "batch_size = 10000\n",
    "for i in range(int(len(X_test)/batch_size)):\n",
    "    \n",
    "    # Do model prediction\n",
    "    inputs = {'data': {\"feats\": X_test[i*batch_size:(i+1)*batch_size]}}\n",
    "    preds = classifier.predict(inputs['data'][\"feats\"])\n",
    "    \n",
    "    # Log model inputs and outputs to monitor concept drift\n",
    "    ids = framework.log(inputs=inputs, outputs=preds)\n",
    "    \n",
    "    # Attach ground truth to corresponding predictions \n",
    "    # in UpTrain framework and identify concept drift\n",
    "    ground_truth = y_test[i*batch_size:(i+1)*batch_size] \n",
    "    framework.log(identifiers=ids, gts=ground_truth)\n",
    "    \n",
    "    # Pausing between batches to monitor progress in the dashboard\n",
    "    time.sleep(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff120f4-97a8-4d0f-aae8-ce18ff0bf326",
   "metadata": {},
   "source": [
    "As we see, we see a sudden (and more alarming) drop using our custom monitors. We can clearly see that the model accuracy drops from 99.7% to 77%, enabling us to send better alerts and take more urgent measures (ex: model retraining) to solve them. \n",
    "\n",
    "<img width=\"624\" alt=\"concept_drift_custom\" src=\"https://user-images.githubusercontent.com/5287871/216795956-a35bcd9f-8b60-439d-9ea2-8e19854390bb.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ac2a23-d962-4a4a-ab08-e5da0d5bfaaf",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c998ab-9381-4d51-a52d-9853828f7e70",
   "metadata": {},
   "source": [
    "Model monitoring is very crucial for tasks such as cyber-attack detection and fraud detection where the attackers continuously improve their attack vectors and with time learn to evade detection. Real-time model observability enables one to proactively address any performance degradation before it leads to serious consequences, such as hacks or financial loss.\n",
    "\n",
    "In this example, we saw two ways to detect performance degradation - Concept Drift via DDM and Custom monitor. The UpTrain framework has many other statistical tools, such as data drift, integrity checks, shift in model outputs, and outlier detection, that can be used to identify model issues, even in cases where ground truth is not available. You can explore them [here](https://github.com/uptrain-ai/uptrain/tree/main/examples)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9545c455b197f2a904e8a44b25c9f43f9436523cf18f2465849be78ad0c6016f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
