{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f76776f-2719-4d42-9836-de37f0c6317c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Context Quality Comparison "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dbf87e-9171-4092-8cbd-782f8e20b8a7",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Overview**: In this notebook, we will compare the quality of retrieved context from Cohere's and OpenAI's embedding models. We have used cosine similarity metric to retrieve the context from the given corpus.\n",
    "\n",
    "We have used Uptrain Standard Eval - Context Relevance to make a judegement on which model is good for the context retrieval purpose.\n",
    "\n",
    "\n",
    "Embed v3 is cohere's latest and most advanced embeddings model. Embed v3 offers state-of-the-art performance per trusted MTEB and BEIR benchmarks. One of the key improvements in Embed v3 is its ability to evaluate how well a query matches a document's topic and assesses the overall quality of the content. This means that it can rank the highest-quality documents at the top, which is especially helpful when dealing with noisy datasets.\n",
    "\n",
    "On the other hand, OpenAI's text-embedding-ada-002 outperforms all the old embedding models on text search, code search, and sentence similarity tasks and gets comparable performance on text classification. \n",
    "\n",
    "For our evaluations, we have used Financial QA dataset. The FiQA dataset has roughly 6,000 questions and 57,000 answers. Financial QA is hard because the vocabularies are context specific. In this experiment, we have randomly picked 100 questions and performed our evaluations on top of it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01e942ec-3f4e-477e-92f1-c98372c10d22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json \n",
    "import polars as pl\n",
    "import os\n",
    "\n",
    "url = \"https://uptrain-assets.s3.ap-south-1.amazonaws.com/data/context_quality_analysis.jsonl\"\n",
    "dataset_path = os.path.join('./', \"context_quality_analysis.jsonl\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    import httpx\n",
    "    r = httpx.get(url)\n",
    "    with open(dataset_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9274f3b9-f791-422e-b3fb-99c3f9e54b87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset= pl.read_ndjson(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4126fdc1-06da-433f-b0c0-9c02a2707896",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (200, 4)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>question</th><th>ground_truth</th><th>context</th><th>embedding_model</th></tr><tr><td>str</td><td>str</td><td>str</td><td>str</td></tr></thead><tbody><tr><td>&quot;Am I exposed t…</td><td>&quot;&quot;Yes, you&#x27;re s…</td><td>&quot;The value of a…</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;Am I exposed t…</td><td>&quot;&quot;Yes, you&#x27;re s…</td><td>&quot;Your definitio…</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;What happen in…</td><td>&quot;&quot;But what happ…</td><td>&quot;If you sold bo…</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;What happen in…</td><td>&quot;&quot;But what happ…</td><td>&quot;1) Yes, both o…</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;How to use a c…</td><td>&quot;&quot;You must buy …</td><td>&quot;&quot;You must buy …</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;How to use a c…</td><td>&quot;&quot;You must buy …</td><td>&quot;&quot;You must buy …</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;Where do I fin…</td><td>&quot;I agree that a…</td><td>&quot;&quot;These warrant…</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;Where do I fin…</td><td>&quot;I agree that a…</td><td>&quot;&quot;These warrant…</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;How do we know…</td><td>&quot;For a company …</td><td>&quot;Generally the …</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;How do we know…</td><td>&quot;For a company …</td><td>&quot;Generally the …</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;When do compan…</td><td>&quot;&quot;In 2005, Appl…</td><td>&quot;From Investope…</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;When do compan…</td><td>&quot;&quot;In 2005, Appl…</td><td>&quot;&quot;In 2005, Appl…</td><td>&quot;openai&quot;</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;In what circum…</td><td>&quot;See if the ban…</td><td>&quot;How would you …</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;In what circum…</td><td>&quot;See if the ban…</td><td>&quot;How would you …</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;What does bank…</td><td>&quot;Does it add to…</td><td>&quot;The extra mone…</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;What does bank…</td><td>&quot;Does it add to…</td><td>&quot;&quot;Usually not t…</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;How can I unde…</td><td>&quot;&quot;Does the comp…</td><td>&quot;The P/E ratio …</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;How can I unde…</td><td>&quot;&quot;Does the comp…</td><td>&quot;Are you implyi…</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;Credit History…</td><td>&quot;It appears all…</td><td>&quot;What happens t…</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;Credit History…</td><td>&quot;It appears all…</td><td>&quot;Some countries…</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;T-mobile stock…</td><td>&quot;&quot;The differenc…</td><td>&quot;&quot;The differenc…</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;T-mobile stock…</td><td>&quot;&quot;The differenc…</td><td>&quot;&quot;The differenc…</td><td>&quot;openai&quot;</td></tr><tr><td>&quot;Why was S&amp;P 50…</td><td>&quot;&quot;Asking why th…</td><td>&quot;&quot;Asking why th…</td><td>&quot;cohere&quot;</td></tr><tr><td>&quot;Why was S&amp;P 50…</td><td>&quot;&quot;Asking why th…</td><td>&quot;&quot;Asking why th…</td><td>&quot;openai&quot;</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (200, 4)\n",
       "┌──────────────────────────┬──────────────────────────┬──────────────────────────┬─────────────────┐\n",
       "│ question                 ┆ ground_truth             ┆ context                  ┆ embedding_model │\n",
       "│ ---                      ┆ ---                      ┆ ---                      ┆ ---             │\n",
       "│ str                      ┆ str                      ┆ str                      ┆ str             │\n",
       "╞══════════════════════════╪══════════════════════════╪══════════════════════════╪═════════════════╡\n",
       "│ Am I exposed to currency ┆ \"Yes, you're still       ┆ The value of a foreign   ┆ cohere          │\n",
       "│ risk wh…                 ┆ exposed to cu…           ┆ stock is …               ┆                 │\n",
       "│ Am I exposed to currency ┆ \"Yes, you're still       ┆ Your definition of       ┆ openai          │\n",
       "│ risk wh…                 ┆ exposed to cu…           ┆ 'outside your…           ┆                 │\n",
       "│ What happen in this      ┆ \"But what happen if the  ┆ If you sold bought a     ┆ cohere          │\n",
       "│ selling call…            ┆ stock pr…                ┆ call option…             ┆                 │\n",
       "│ What happen in this      ┆ \"But what happen if the  ┆ 1) Yes, both of your     ┆ openai          │\n",
       "│ selling call…            ┆ stock pr…                ┆ scenarios w…             ┆                 │\n",
       "│ …                        ┆ …                        ┆ …                        ┆ …               │\n",
       "│ T-mobile stock:          ┆ \"The difference between  ┆ \"The difference between  ┆ cohere          │\n",
       "│ difference betwe…        ┆ TMUSP an…                ┆ TMUSP an…                ┆                 │\n",
       "│ T-mobile stock:          ┆ \"The difference between  ┆ \"The difference between  ┆ openai          │\n",
       "│ difference betwe…        ┆ TMUSP an…                ┆ TMUSP an…                ┆                 │\n",
       "│ Why was S&P 500 PE Ratio ┆ \"Asking why the p/e was  ┆ \"Asking why the p/e was  ┆ cohere          │\n",
       "│ so high…                 ┆ so high …                ┆ so high …                ┆                 │\n",
       "│ Why was S&P 500 PE Ratio ┆ \"Asking why the p/e was  ┆ \"Asking why the p/e was  ┆ openai          │\n",
       "│ so high…                 ┆ so high …                ┆ so high …                ┆                 │\n",
       "└──────────────────────────┴──────────────────────────┴──────────────────────────┴─────────────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc34b865-e278-4369-b4d7-9a13fbbf3abb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cff315ca-ef13-4716-870f-0d6e191ce130",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = dataset.to_dicts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0cba599-c455-44c9-ab23-c6f8b994d8f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Running Uptrain Eval - Context Relevancy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6697342f-340d-4b84-b722-38daac377eff",
   "metadata": {
    "tags": []
   },
   "source": [
    "### OpenAI Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "010316d6-8288-4f69-a2f1-43a19621c57a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from uptrain import APIClient, Evals, ResponseMatching\n",
    "UPTRAIN_API_KEY = \"up-*********************\" ## INSERT YOUR UPTRAIN KEY HERE\n",
    "\n",
    "client = APIClient(uptrain_api_key=UPTRAIN_API_KEY)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "baaa4bfe-50db-4c7c-92ae-4f80955ccac8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['question', 'ground_truth', 'context', 'embedding_model'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "d1147b6a-2860-432a-81c6-f60359903074",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-15 00:30:15.145\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.framework.remote\u001b[0m:\u001b[36mlog_and_evaluate\u001b[0m:\u001b[36m455\u001b[0m - \u001b[1mSending evaluation request for rows 0 to <50 to the Uptrain server\u001b[0m\n",
      "\u001b[32m2023-11-15 00:30:31.045\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.framework.remote\u001b[0m:\u001b[36mlog_and_evaluate\u001b[0m:\u001b[36m455\u001b[0m - \u001b[1mSending evaluation request for rows 50 to <100 to the Uptrain server\u001b[0m\n",
      "\u001b[32m2023-11-15 00:30:44.670\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.framework.remote\u001b[0m:\u001b[36mlog_and_evaluate\u001b[0m:\u001b[36m455\u001b[0m - \u001b[1mSending evaluation request for rows 100 to <150 to the Uptrain server\u001b[0m\n",
      "\u001b[32m2023-11-15 00:30:57.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.framework.remote\u001b[0m:\u001b[36mlog_and_evaluate\u001b[0m:\u001b[36m455\u001b[0m - \u001b[1mSending evaluation request for rows 150 to <200 to the Uptrain server\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "results = client.evaluate_experiments(\n",
    "    project_name=\"context_analysis\",\n",
    "    data = dataset, \n",
    "    checks = [Evals.CONTEXT_RELEVANCE], \n",
    "    exp_columns = ['embedding_model']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0addf8e3-c16f-481e-9cfe-e2ffcc8a735d",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Comparitive Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "a452f2d6-d81c-49c2-be6b-add4286cfbf1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'How do I pay my estimated income tax?'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[7]['question']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ffa97-a0af-4f91-aa8a-e368b0895930",
   "metadata": {},
   "source": [
    "To print context from both models, please uncomment and run the next cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "966367bc-1181-4ad8-96b2-ddd65ce7988b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print('Question:', results[7]['question'])\n",
    "# print('Cohere context:', results[7]['context_embedding_model_cohere'])\n",
    "# print()\n",
    "# print('OpenAI context:', results[7]['context_embedding_model_openai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c29b1c-8127-4b2e-a5fe-e1b5babe33a1",
   "metadata": {
    "tags": []
   },
   "source": [
    "In this example, we can clearly see that the context retrieved from the cohere's embed v3 model has all the required content to answer this particular question. For instance, the notion of 'self-employment' tax is only retrieved in cohere's model context whereas OpenAI's model context does not mention about this particular tax. \n",
    "\n",
    "OpenAI context contains relevant information to answer this question but Cohere's context is much better to answer this question from holistic view.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "371a3245-8ae6-4c8c-8908-a5d4eab571e7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context Relevance Score using Embed v3 model: 1.0\n",
      "Context Relevance Score using OpenAI model: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Context Relevance Score using Embed v3 model:', results[7]['score_context_relevance_embedding_model_cohere'])\n",
    "print('Context Relevance Score using OpenAI model:', results[7]['score_context_relevance_embedding_model_openai'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6e573d4-a5a7-4b22-9528-46b036c25e7d",
   "metadata": {},
   "source": [
    "The same conclusion can be achieved by running the Uptrain Standard Eval - Context Relevance. We can see that the context retrieved from the embed v3 model has got a score of 1.0 while the context retrieved from the OpenAI embedding model has a score of 0.5. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df0e7e0-d8e3-4a99-9bd2-6f9403ebc786",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8724367b-2c20-423d-8108-88f7f323a454",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "score_context_relevance_openai = list(pl.DataFrame(results)['score_context_relevance_embedding_model_openai'])\n",
    "score_context_relevance_cohere = list(pl.DataFrame(results)['score_context_relevance_embedding_model_cohere'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "26965be5-84bc-4e54-8161-30fab1ea35a1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Context Relevancy Score using OpenAI model: 0.49\n",
      "Average Context Relevancy Score using Embed v3 model: 0.595\n"
     ]
    }
   ],
   "source": [
    "print('Average Context Relevancy Score using OpenAI model:', sum(score_context_relevance_openai)/len(score_context_relevance_openai))\n",
    "print('Average Context Relevancy Score using Embed v3 model:', sum(score_context_relevance_cohere)/len(score_context_relevance_cohere))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985602fb-59b1-4618-9533-ada56c76ca45",
   "metadata": {},
   "source": [
    "Empirically, this shows that the context retrieved from the Embed v3 model is of better quality in comparison to the OpenAI embedding model. \n",
    "\n",
    "The same analysis can be seen from the graph as well. The graph can be obtained from Uptrain dashboard by providing the uptrain API key."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9209ccbd-addb-4926-9b3d-ef727d3f6dc5",
   "metadata": {
    "tags": []
   },
   "source": [
    "<img src=\"https://uptrain-assets.s3.ap-south-1.amazonaws.com/data/context_analysis.png\" alt=\"Alternative text\" />\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cb40d9-88c7-4f82-a0b2-31813fd42c17",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
