{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use UpTrain to validate LLM responses"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**: In this example, we will see how to validate your LLM responses before passing them to downstream tasks. The validation is done on the list of checks defined where UpTrain retries the LLM till it gets a valid response. We will be using a QnA task to highlight the same."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is validation needed**: Well, LLMs are great but they can also go horribly wrong. Your downstream tasks expect the LLM response in a certain structure and for certain cases, that might not be the case. LLMs can hallucinate randomly, and you definitely don't want to show those results to your users. Hence, you want to run validation checks on our LLM responses, retry if they are wrong, and output only the final valid responses which pass all the checks."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task Setup**: The workflow of our hypothetical QnA application goes like,\n",
    "- User enters a natural language query. \n",
    "- The query is converted to an embedding, and relevant sections from the documentation are retrieved using nearest neighbor search. \n",
    "- The original query along with the retrieved sections is passed to a language model (LM), along with a custom prompt to generate a response. \n",
    "\n",
    "We use a dataset built from logs generated by a chatbot made to answer questions from the [Streamlit user documentation](https://docs.streamlit.io/). "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**: We illustate how to use the Uptrain Validation framework to validate the performance of the chatbot. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install required packages\n",
    "\n",
    "```bash\n",
    "pip install uptrain[full]  # Install UpTrain with all dependencies\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure to define openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"...\"\n",
    "os.environ['OPENAI_API_KEY'] = open(\"/Users/sourabhagrawal/Desktop/codes/llm/uptrain_experiments/uptrain_experiments/manager/key.txt\", \"r\").read()\n",
    "import openai\n",
    "import polars as pl\n",
    "\n",
    "openai.api_key = open(\"/Users/sourabhagrawal/Desktop/codes/llm/uptrain_experiments/uptrain_experiments/manager/key.txt\", \"r\").read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's first define our prompt and model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have designed the prompt to take in a question and a document and extract the relevant sections from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    You are a developer assistant that can only quote text from documents. \n",
    "    You will be given a section of technical documentation titled {document_title}.\n",
    "    \n",
    "    The input is: '{question}?'. \n",
    "\n",
    "    Your task is to quote exactly all sections of the document that are relevant to any topics of the input. \n",
    "    Copy the text exactly as found in the original document. \n",
    "    \n",
    "    Okay, here is the document:\n",
    "    --- START: Document ---\n",
    "    \n",
    "    {document_text}\n",
    "\n",
    "    -- END: Document ---\n",
    "    Now do the task. If there are no relevant sections, just respond with \\\"<EMPTY MESSAGE>\\\".\n",
    "    \n",
    "    Here are the exact sections from the document:\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load our dataset and see how that looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 3)\n",
      "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
      "‚îÇ question                    ‚îÜ document_title               ‚îÜ document_text                       ‚îÇ\n",
      "‚îÇ ---                         ‚îÜ ---                          ‚îÜ ---                                 ‚îÇ\n",
      "‚îÇ str                         ‚îÜ str                          ‚îÜ str                                 ‚îÇ\n",
      "‚ïû‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï™‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ï°\n",
      "‚îÇ How to use the sessionstate ‚îÜ What is serializable session ‚îÜ ## Serializable Session State       ‚îÇ\n",
      "‚îÇ feat‚Ä¶                       ‚îÜ sta‚Ä¶                         ‚îÜ                                     ‚îÇ\n",
      "‚îÇ                             ‚îÜ                              ‚îÜ S‚Ä¶                                  ‚îÇ\n",
      "‚îÇ How can I create histograms ‚îÜ API reference                ‚îÜ ader(\"Define a custom colorscale‚Ä¶   ‚îÇ\n",
      "‚îÇ with‚Ä¶                       ‚îÜ                              ‚îÜ                                     ‚îÇ\n",
      "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[/Users/runner/work/polars/polars/polars/polars-io/src/ndjson/core.rs:162] &data_type = Struct(\n",
      "    [\n",
      "        Field {\n",
      "            name: \"question\",\n",
      "            data_type: LargeUtf8,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"document_title\",\n",
      "            data_type: LargeUtf8,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"document_link\",\n",
      "            data_type: LargeUtf8,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"document_text\",\n",
      "            data_type: LargeUtf8,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"answer\",\n",
      "            data_type: LargeUtf8,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"question_idx\",\n",
      "            data_type: Int64,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"row_idx\",\n",
      "            data_type: Int64,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"model\",\n",
      "            data_type: LargeUtf8,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"idx\",\n",
      "            data_type: Int64,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"Template\",\n",
      "            data_type: Int64,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"persona\",\n",
      "            data_type: LargeUtf8,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"response\",\n",
      "            data_type: LargeUtf8,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"experiment_id\",\n",
      "            data_type: Int64,\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"question_embeddings\",\n",
      "            data_type: LargeList(\n",
      "                Field {\n",
      "                    name: \"item\",\n",
      "                    data_type: Float64,\n",
      "                    is_nullable: true,\n",
      "                    metadata: {},\n",
      "                },\n",
      "            ),\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"context_embeddings\",\n",
      "            data_type: LargeList(\n",
      "                Field {\n",
      "                    name: \"item\",\n",
      "                    data_type: Float64,\n",
      "                    is_nullable: true,\n",
      "                    metadata: {},\n",
      "                },\n",
      "            ),\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "        Field {\n",
      "            name: \"response_embeddings\",\n",
      "            data_type: LargeList(\n",
      "                Field {\n",
      "                    name: \"item\",\n",
      "                    data_type: Float64,\n",
      "                    is_nullable: true,\n",
      "                    metadata: {},\n",
      "                },\n",
      "            ),\n",
      "            is_nullable: true,\n",
      "            metadata: {},\n",
      "        },\n",
      "    ],\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "url = \"https://oodles-dev-training-data.s3.us-west-1.amazonaws.com/qna-streamlit-docs.jsonl\"\n",
    "dataset_path = os.path.join(\"datasets\", \"qna-notebook-data.jsonl\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    import httpx\n",
    "    r = httpx.get(url)\n",
    "    with open(dataset_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "dataset = pl.read_ndjson(dataset_path).select(pl.col(['question', 'document_title', 'document_text']))\n",
    "print(dataset[0:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now define our completion function i.e. how we get response from our LLM. We are using GPT-3.5-Turbo for the same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_response(input_dictn):\n",
    "    prompt = [{\"role\": \"system\", \"content\": prompt_template.format(**input_dictn)}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=prompt,\n",
    "        temperature=0.1\n",
    "    )\n",
    "    message = response.choices[0]['message']['content']\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we complete our setup, let's try out few examples to see how this looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_question': 'How to use the sessionstate feature in Streamlit', 'llm_response': 'By default, Streamlit‚Äôs [Session State](https://docs.streamlit.io/library/advanced-features/session-state) allows you to persist any Python object for the duration of the session, irrespective of the object‚Äôs pickle-serializability.\\n\\nTo that end, Streamlit provides a `runner.enforceSerializableSessionState` [configuration option](https://docs.streamlit.io/library/advanced-features/configuration) that, when set to `true`, only allows pickle-serializable objects in Session State.'} \n",
      "\n",
      "{'input_question': 'How can I create histograms with different bucket colors in Streamlit', 'llm_response': '```\\nader(\"Define a custom colorscale\")\\ndf = px.data.iris()\\nfig = px.scatter(\\n    df,\\n    x=\"sepal_width\",\\n    y=\"sepal_length\",\\n    color=\"sepal_length\",\\n    color_continuous_scale=\"reds\",\\n)\\n```\\n```\\nNotice how the custom color scale is still reflected in the chart, even when the Streamlit theme is enabled üëá\\n\\nFor many more examples of Plotly charts with and without the Streamlit theme, check out the [plotly.streamlit.app](https://plotly.streamlit.app).\\n```'} \n",
      "\n",
      "{'input_question': 'Can I create histograms with different bucket colors in Streamlit', 'llm_response': '<EMPTY MESSAGE>'} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print({'input_question': dataset['question'][0], 'llm_response': get_model_response(dataset.to_dicts()[0])}, \"\\n\")\n",
    "print({'input_question': dataset['question'][1], 'llm_response': get_model_response(dataset.to_dicts()[1])}, \"\\n\")\n",
    "print({'input_question': dataset['question'][4], 'llm_response': get_model_response(dataset.to_dicts()[5])}, \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we notice from our prompt, our model can give empty responses for certain cases. Let's see how we can use UpTrain validation framework to check for the same and retry whenever that happens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Validation Framework to check for empty responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a simple check to check if the model response is empty or not. We utilize the pre-built TextComparison operator for the same. This creates a new variable called 'is_empty_response' by running this check on our input data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uptrain.framework import SimpleCheck, Signal\n",
    "from uptrain.operators import (\n",
    "    SelectOp,\n",
    ")\n",
    "from uptrain.operators.language import (\n",
    "    TextComparison,\n",
    ")\n",
    "from validation_wrapper import ValidationManager\n",
    "\n",
    "check = SimpleCheck(\n",
    "        name=\"empty_response_validation\",\n",
    "        sequence=[\n",
    "            SelectOp(\n",
    "                columns={\n",
    "                    \"is_empty_response\": TextComparison(\n",
    "                        reference_text=\"<EMPTY MESSAGE>\",\n",
    "                        col_in_text=\"response\",\n",
    "                    ),\n",
    "                }\n",
    "            )\n",
    "        ],\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define our pass condition as whenever the response is not empty. UpTrain provides a nice wrapper called Signal which allows you to define this pass condition by utilizing mathematical operators (like ~, &, |, +, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_condition = ~Signal('is_empty_response')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UpTrain provides a validation manager class where you pass your check, completion_function, and pass_condition. Now, instead of calling the completion_function, you simply call validation_manager.run with your inputs, and under the hood, it computes the check, see if the pass condition is true, and if not, retry before outputting the LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_manager = ValidationManager(\n",
    "    check=check,\n",
    "    completion_fn=get_model_response,\n",
    "    pass_condition=~Signal('is_empty_response')\n",
    ")\n",
    "validation_manager.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run on our input dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-29 23:16:24.662\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:16:27.547\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:16:28.893\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:16:32.142\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:16:34.765\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:16:35.207\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:16:35.631\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:16:36.067\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:16:36.494\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:16:49.202\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:05.384\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:07.972\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:11.981\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:21.519\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:22.944\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:24.167\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:38.782\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:43.399\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:54.307\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:17:58.889\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:00.921\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:01.749\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:12.482\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:26.016\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:39.034\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:43.561\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:44.029\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:44.424\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:44.872\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:45.312\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:18:51.144\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:03.037\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:15.624\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:27.216\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:31.169\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:36.051\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:43.018\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:45.628\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:48.632\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:51.157\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:53.438\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:54.020\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:54.492\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:55.114\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:19:55.557\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:20:08.125\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:20:20.370\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:20:23.024\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:20:25.232\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:20:35.855\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:20:37.085\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:20:38.180\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:20:53.407\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:20:56.585\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:21:10.189\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:21:14.697\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:21:16.730\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:21:17.850\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:21:29.393\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:21:41.852\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:21:55.471\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:22:00.261\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:22:00.706\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:22:01.353\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:22:01.814\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:22:02.273\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-06-29 23:22:05.857\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m106\u001b[0m - \u001b[34m\u001b[1mExecuting node: sequence_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inputs in dataset.to_dicts():\n",
    "    validated_response = validation_manager.run(inputs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
