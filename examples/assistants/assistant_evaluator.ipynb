{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyanshjain/Documents/UpTrain/GitHub_Clone/uptrain/.venv/lib/python3.11/site-packages/lazy_loader/__init__.py:185: RuntimeWarning: subpackages can technically be lazily loaded, but it causes the package to be eagerly loaded even if it is already lazily loaded.So, you probably shouldn't use subpackages with this lazy feature.\n",
      "  warnings.warn(msg, RuntimeWarning)\n",
      "/Users/shreyanshjain/Documents/UpTrain/GitHub_Clone/uptrain/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from uptrain import EvalAssistant\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the inputs for your AI assistant:\n",
    "- `user_bot_name`: Your bot name\n",
    "\n",
    "- `user_bot_instructions`: The original set of prompts you want to use to test your assistant\n",
    "\n",
    "- `user_bot_file_list`: The path to the files which act as your knowledge base\n",
    "\n",
    "- `user_bot_model`(optional): The LLM model you want to use (we will use `gpt-4-1106-preview` by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_bot_name = 'Nurse Bot v1'\n",
    "\n",
    "user_bot_instructions = \"You are an expert, professional nurse who is supposed to answer patient queries on different medical scenarios to patients.\"\n",
    "\n",
    "user_bot_file_list = ['context_docs/nurse_doc.docx','context_docs/covid_faq.pdf','context_docs/malaria.pdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's set the arguments for the evaluator:\n",
    "\n",
    "- `user_bot_purpose`: A small description of the purpose of your bot\n",
    "\n",
    "- `evaluator_persona`: List of different persona (or scenarios) you wish to test your bot on. \n",
    "\n",
    "- `evaluator_bot_model`(optional): The LLM model you want to use (we will use `gpt-4-1106-preview` by default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Scenario to evaluate #########\n",
    "\n",
    "user_bot_purpose = 'Answer patient queries on different medical scenarios to patients'\n",
    "\n",
    "evaluator_persona = [\n",
    "    \"Elderly patient asking about the symptoms of COVID 19\",\n",
    "    # \"Anxious patient preparing for surgery\",\n",
    "    # \"A mother whose teenage son is suffering from Malaria\",\n",
    "    # \"An anxious patient irritated about the pain he is facing due to chicken pox medicines\"\n",
    "    # \"New parent asking about infant feeding\",\n",
    "    # \"Chronic pain patient managing arthritis\",\n",
    "    # \"Teenager seeking advice on acne treatment\",\n",
    "    # \"Caregiver looking for tips on dementia care\",\n",
    "    # \"Busy professional with flu symptoms\",\n",
    "    # \"Non-native speaker asking about medication side effects\"\n",
    "    # \"A patient who talks in pronouns\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Answer patient queries on different medical scenarios to patients'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_bot_purpose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's simulate the conversations based on these personas\n",
    "\n",
    "By default, we will generate 4 pairs of conversation for each scenario. If you wish to change that, let's say to 10 conversation pairs, you can simply do so by adding an argument: `trial_count = 10`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-04-03 19:08:23.501\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.framework.eval_assistant.assistant_evals_utils\u001b[0m:\u001b[36msimulate_conversation\u001b[0m:\u001b[36m202\u001b[0m - \u001b[1mStep 1 of 1 Completed\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      Symptoms: Provide information on common sympto...\n",
      "1       Include advice on when to seek medical attent...\n",
      "2       COVID-19 Information: Explain the symptoms, t...\n",
      "3       Include details on testing and quarantine gui...\n",
      "4       Medication Information: Provide guidance on c...\n",
      "                             ...                        \n",
      "651                                                 936)\n",
      "652     \\n• Management of severe malaria: a practical...\n",
      "653                        \\n• World malaria report 2016\n",
      "654             Geneva: World Health Org anization; 2016\n",
      "655                                                  \\n \n",
      "Name: chunk, Length: 656, dtype: object\n",
      "1\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "assistant_eval_client = EvalAssistant(openai_api_key=os.environ[\"OPENAI_API_KEY\"])\n",
    "\n",
    "message =  assistant_eval_client.simulate_conversation(\n",
    "    user_bot_name = user_bot_name,\n",
    "    user_bot_instructions = user_bot_instructions,\n",
    "    user_bot_purpose = user_bot_purpose,\n",
    "    user_bot_file_list = user_bot_file_list,\n",
    "    evaluator_persona_list = evaluator_persona,\n",
    "    trial_count= 2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/shreyanshjain/Documents/UpTrain/GitHub_Clone/uptrain/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "text = \"efvhefvehfv b3jr 3r3  3r3r3r3r3r r3r3gg3 3r3r3r 3r3r3r \"\n",
    "\n",
    "from uptrain.utilities import lazy_load_dep\n",
    "encoder = SentenceTransformer(\"paraphrase-mpnet-base-v2\")\n",
    "vectors = encoder.encode(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's evaluate these simulated conversations\n",
    "\n",
    "We will use UpTrain's [Conversation Satisfaction](https://docs.uptrain.ai/predefined-evaluations/conversation-evals/user-satisfaction) to test whether the user seems satisfied with the assistant's responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uptrain import ConversationSatisfaction, Evals\n",
    "\n",
    "results = assistant_eval_client.evaluate(\n",
    "    data = message,\n",
    "    checks = [ConversationSatisfaction(llm_persona = user_bot_purpose), Evals.FACTUAL_ACCURACY, Evals.RESPONSE_RELEVANCE, Evals.CONTEXT_RELEVANCE, Evals.RESPONSE_CONCISENESS])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[0]['conversation']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
