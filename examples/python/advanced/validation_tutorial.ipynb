{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use UpTrain to validate LLM responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Overview**: In this example, we will see how you can use UpTrain to ensure that your LLM responses are adequate before you use them to perform downstream tasks. A list of defined checks performs the validation. If the LLM's response is invalid, UpTrain will keep retrying until the model returns a valid one. We will use a Q&A task as an example to highlight the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Why is validation Needed**: LLMs are great, but they are not 100% reliable. Downstream tasks require the LLM response in a particular structure. Sometimes the response produced by the LLM deviates from the required format. This deviation causes all sorts of problems. LLMs can hallucinate randomly. We surely don't want to show those results to our users. Hence, we have to run validation checks on our LLM responses, catch where they go wrong and retry the LLMs. This process repeats until the LLM output passes all the validation checks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Problem**: The workflow of our hypothetical Q&A application goes like this,\n",
    "- User enters a question. \n",
    "- The query converts to an embedding, and relevant sections from the documentation are retrieved using nearest neighbour search. \n",
    "- The original query and the retrieved sections are passed to a language model (LM), along with a custom prompt to generate a response. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Solution**: We will illustrate how to use the \"Uptrain Validation framework\" to validate the performance of the chatbot. We will use a dataset built from logs generated by a chatbot made to answer questions from the [Streamlit user documentation](https://docs.streamlit.io/). \n",
    "\n",
    "**Validation Logic**: We will check if the LLM response is empty or not for the given query. If empty, we want to return a default message instead of the LLM response."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install UpTrain with all dependencies\n",
    "\n",
    "```bash\n",
    "pip install uptrain\n",
    "uptrain-add --feature full\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure to define openai_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import polars as pl\n",
    "import json"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This notebook uses the OpenAI API to generate text for prompts, make sure the env variable is populated with the API key.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.environ[\"OPENAI_API_KEY\"] = \"...\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's first define our prompt and model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have designed a prompt template to take in a question and a document and extract the relevant sections from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\n",
    "    You are a developer assistant that can only quote text from documents. \n",
    "    You will be given a section of technical documentation titled {document_title}.\n",
    "    \n",
    "    The input is: '{question}?'. \n",
    "\n",
    "    Your task is to answer the question by quoting exactly all sections of the document that are relevant to any topics of the input. \n",
    "    Copy the text exactly as found in the original document. \n",
    "    \n",
    "    Okay, here is the document:\n",
    "    --- START: Document ---\n",
    "    \n",
    "    {document_text}\n",
    "\n",
    "    -- END: Document ---\n",
    "    Now do the task. If there are no relevant sections, just respond with \\\"<EMPTY MESSAGE>\\\".\n",
    "    \n",
    "    Here is the answer:\n",
    "\"\"\"\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now load our dataset and see how that looks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of test cases:  90\n",
      "Couple of samples:  shape: (2, 3)\n",
      "┌─────────────────────────────┬──────────────────────────────┬─────────────────────────────────────┐\n",
      "│ question                    ┆ document_title               ┆ document_text                       │\n",
      "│ ---                         ┆ ---                          ┆ ---                                 │\n",
      "│ str                         ┆ str                          ┆ str                                 │\n",
      "╞═════════════════════════════╪══════════════════════════════╪═════════════════════════════════════╡\n",
      "│ How to use the sessionstate ┆ What is serializable session ┆ ## Serializable Session State\\n\\…   │\n",
      "│ feat…                       ┆ sta…                         ┆                                     │\n",
      "│ How can I create histograms ┆ API reference                ┆ ader(\\\"Define a custom colorscal…   │\n",
      "│ with…                       ┆                              ┆                                     │\n",
      "└─────────────────────────────┴──────────────────────────────┴─────────────────────────────────────┘\n"
     ]
    }
   ],
   "source": [
    "url = \"https://oodles-dev-training-data.s3.us-west-1.amazonaws.com/qna-streamlit-docs.jsonl\"\n",
    "dataset_path = os.path.join(\"datasets\", \"qna-notebook-data.jsonl\")\n",
    "\n",
    "if not os.path.exists(dataset_path):\n",
    "    import httpx\n",
    "\n",
    "    r = httpx.get(url)\n",
    "    with open(dataset_path, \"wb\") as f:\n",
    "        f.write(r.content)\n",
    "\n",
    "dataset = pl.read_ndjson(dataset_path).select(\n",
    "    pl.col([\"question\", \"document_title\", \"document_text\"])\n",
    ")\n",
    "print(\"Number of test cases: \", len(dataset))\n",
    "print(\"Couple of samples: \", dataset[0:2])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now get responses from our LLM by defining our completion function. \n",
    "We are using GPT-3.5-Turbo for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_response(input_dict):\n",
    "    prompt = [{\"role\": \"system\", \"content\": prompt_template.format(**input_dict)}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=prompt, temperature=0.1\n",
    "    )\n",
    "    message = response.choices[0][\"message\"][\"content\"]\n",
    "    return message"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have completed the setup, let's try out a few examples to see how they look."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      " \"input_question\": \"How to use the sessionstate feature in Streamlit\",\n",
      " \"llm_response\": \"By default, Streamlit\\u2019s [Session State](https://docs.streamlit.io/library/advanced-features/session-state) allows you to persist any Python object for the duration of the session, irrespective of the object\\u2019s pickle-serializability. This property lets you store Python primitives such as integers, floating-point numbers, complex numbers and booleans, dataframes, and even [lambdas](https://docs.python.org/3/reference/expressions.html#lambda) returned by functions. However, some execution environments may require serializing all data in Session State, so it may be useful to detect incompatibility during development, or when the execution environment will stop supporting it in the future.\\n\\nTo that end, Streamlit provides a `runner.enforceSerializableSessionState` [configuration option](https://docs.streamlit.io/library/advanced-features/configuration) that, when set to `true`, only allows pickle-serializable objects in Session State.\"\n",
      "} \n",
      "\n",
      "{\n",
      " \"input_question\": \"How can I create histograms with different bucket colors in Streamlit\",\n",
      " \"llm_response\": \"```\\nader(\\\"Define a custom colorscale\\\")\\ndf = px.data.iris()\\nfig = px.scatter(\\n    df,\\n    x=\\\"sepal_width\\\",\\n    y=\\\"sepal_length\\\",\\n    color=\\\"sepal_length\\\",\\n    color_continuous_scale=\\\"reds\\\",\\n)\\n\\ntab1, tab2 = st.tabs([\\\"Streamlit theme (default)\\\", \\\"Plotly native theme\\\"])\\nwith tab1:\\n    st.plotly_chart(fig, theme=\\\"streamlit\\\", use_container_width=True)\\nwith tab2:\\n    st.plotly_chart(fig, theme=None, use_container_width=True)\\n\\n```\\nNotice how the custom color scale is still reflected in the chart, even when the Streamlit theme is enabled \\ud83d\\udc47\\n\\nFor many more examples of Plotly charts with and without the Streamlit theme, check out the [plotly.streamlit.ap\"\n",
      "} \n",
      "\n",
      "{\n",
      " \"input_question\": \"How to use the sessionstate feature in Streamlit\",\n",
      " \"llm_response\": \"<EMPTY MESSAGE>\"\n",
      "} \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    json.dumps(\n",
    "        {\n",
    "            \"input_question\": dataset[\"question\"][0],\n",
    "            \"llm_response\": get_model_response(dataset.to_dicts()[0]),\n",
    "        },\n",
    "        indent=1,\n",
    "    ),\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    json.dumps(\n",
    "        {\n",
    "            \"input_question\": dataset[\"question\"][1],\n",
    "            \"llm_response\": get_model_response(dataset.to_dicts()[1]),\n",
    "        },\n",
    "        indent=1,\n",
    "    ),\n",
    "    \"\\n\",\n",
    ")\n",
    "print(\n",
    "    json.dumps(\n",
    "        {\n",
    "            \"input_question\": dataset[\"question\"][5],\n",
    "            \"llm_response\": get_model_response(dataset.to_dicts()[5]),\n",
    "        },\n",
    "        indent=1,\n",
    "    ),\n",
    "    \"\\n\",\n",
    ")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, our model gives us empty responses for certain cases. Let's see how we can use the UpTrain Validation Framework to check for the same and retry the LLM whenever that happens."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Validation Framework to check for empty responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the Validation Checks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a `Check` to evaluate if the model response is empty or not. We utilize the pre-built `TextComparison` operator for the same. After running this on our input data a new variable called 'is_empty_response' is created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uptrain.framework import Check\n",
    "from uptrain.operators import TextComparison\n",
    "\n",
    "check = Check(\n",
    "    name=\"empty_response_validation\",\n",
    "    operators=[\n",
    "        TextComparison(\n",
    "            reference_texts=\"<EMPTY MESSAGE>\",\n",
    "            col_in_text=\"response\",\n",
    "            col_out=\"is_empty_response\",\n",
    "        ),\n",
    "    ],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the passing condition"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our pass condition is defined as \"any response that is not empty\". UpTrain provides a wrapper function called Signal which allows us to define the pass condition by utilizing mathematical operators (like ~, &, |, +, etc.).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uptrain.framework import Signal\n",
    "\n",
    "pass_condition = ~Signal(\"is_empty_response\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the retry logic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the retry logic which dictates how to generate LLM responses in case of validation failures. This could be any python function like modifying prompt, temperature, triggering a tool, returning a default response, etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_response_when_empty(input_dict):\n",
    "    return f\"We couldn't find a good enough answer for the given question: {input_dict['question']}. Please try asking a different question\"\n",
    "\n",
    "# Call 'model_response_when_empty' when response is empty\n",
    "retry_logic=[{\n",
    "        \"name\": \"default_output_when_response_is_empty\",\n",
    "        \"signal\": Signal(\"is_empty_response\"),\n",
    "        \"completion_function\": model_response_when_empty\n",
    "    }\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UpTrain provides a `ValidationManager` class that allows us to pass the `Check`, completion_function and pass_condition. Instead of calling the completion_function, we can call validation_manager. Under the hood, it computes the check, makes sure the pass condition is validated, and if the pass condition is not validated, it will retry until it outputs the correct LLM response."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tying everything together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from uptrain.validation_wrapper import ValidationManager\n",
    "\n",
    "validation_manager = ValidationManager(\n",
    "    check=check,\n",
    "    completion_function=get_model_response,\n",
    "    retry_logic=retry_logic,\n",
    "    pass_condition=pass_condition,\n",
    ")\n",
    "validation_manager.setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's run our example"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's run it a few values from our input dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:04.499\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:04.705\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:05.209\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:05.212\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[33m\u001b[1mRETRYING validation check 1 of 3 with logic: default_output_when_response_is_empty\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:05.213\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:05.214\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 2 attempt(s)\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:05.215\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mResponse History: {'attempt_0': '<EMPTY MESSAGE>', 'attempt_1': \"We couldn't find a good enough answer for the given question: ['How can I create histograms with different bucket colors in Streamlit']. Please try asking a different question\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:05.651\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:05.653\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[33m\u001b[1mRETRYING validation check 1 of 3 with logic: default_output_when_response_is_empty\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:05.654\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:05.655\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 2 attempt(s)\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:05.655\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mResponse History: {'attempt_0': '<EMPTY MESSAGE>', 'attempt_1': \"We couldn't find a good enough answer for the given question: ['Can I create histograms with different bucket colors in Streamlit']. Please try asking a different question\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:06.103\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:06.106\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[33m\u001b[1mRETRYING validation check 1 of 3 with logic: default_output_when_response_is_empty\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:06.106\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:06.107\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 2 attempt(s)\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:06.108\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mResponse History: {'attempt_0': '<EMPTY MESSAGE>', 'attempt_1': \"We couldn't find a good enough answer for the given question: ['Can I create histograms with different bucket colors in Streamlit']. Please try asking a different question\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:06.568\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:06.569\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[33m\u001b[1mRETRYING validation check 1 of 3 with logic: default_output_when_response_is_empty\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:06.570\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:06.571\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 2 attempt(s)\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:06.571\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mResponse History: {'attempt_0': '<EMPTY MESSAGE>', 'attempt_1': \"We couldn't find a good enough answer for the given question: ['Can I create histograms with different bucket colors in Streamlit']. Please try asking a different question\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:07.155\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:07.157\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[33m\u001b[1mRETRYING validation check 1 of 3 with logic: default_output_when_response_is_empty\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:07.157\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:07.158\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 2 attempt(s)\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:07.159\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mResponse History: {'attempt_0': '<EMPTY MESSAGE>', 'attempt_1': \"We couldn't find a good enough answer for the given question: ['How to use the sessionstate feature in Streamlit']. Please try asking a different question\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:08.383\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:08.385\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:20.687\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:20.694\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:22.565\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:22.567\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[33m\u001b[1mRETRYING validation check 1 of 3 with logic: default_output_when_response_is_empty\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:22.568\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:22.569\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 2 attempt(s)\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:22.570\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mResponse History: {'attempt_0': '<EMPTY MESSAGE>', 'attempt_1': \"We couldn't find a good enough answer for the given question: ['How can I create histograms with different bucket colors in Streamlit']. Please try asking a different question\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:22.982\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:22.987\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[33m\u001b[1mRETRYING validation check 1 of 3 with logic: default_output_when_response_is_empty\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:22.988\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:22.988\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 2 attempt(s)\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:22.989\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mResponse History: {'attempt_0': '<EMPTY MESSAGE>', 'attempt_1': \"We couldn't find a good enough answer for the given question: ['How can I create histograms with different bucket colors in Streamlit']. Please try asking a different question\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:34.339\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:34.360\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:38.181\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:38.187\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:38.660\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:38.662\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[33m\u001b[1mRETRYING validation check 1 of 3 with logic: default_output_when_response_is_empty\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:38.663\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:38.665\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 2 attempt(s)\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:38.666\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mResponse History: {'attempt_0': '<EMPTY MESSAGE>', 'attempt_1': \"We couldn't find a good enough answer for the given question: ['Can I create histograms with different bucket colors in Streamlit']. Please try asking a different question\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:52.842\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:52.850\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:30:58.211\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:30:58.214\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:31:10.665\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:31:10.675\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:31:14.413\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:31:14.415\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:31:14.882\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:31:14.883\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m46\u001b[0m - \u001b[33m\u001b[1mRETRYING validation check 1 of 3 with logic: default_output_when_response_is_empty\u001b[0m\n",
      "\u001b[32m2023-07-28 14:31:14.883\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:31:14.884\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 2 attempt(s)\u001b[0m\n",
      "\u001b[32m2023-07-28 14:31:14.884\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m51\u001b[0m - \u001b[1mResponse History: {'attempt_0': '<EMPTY MESSAGE>', 'attempt_1': \"We couldn't find a good enough answer for the given question: ['How can I create histograms with different bucket colors in Streamlit']. Please try asking a different question\"}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:31:16.175\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:31:16.178\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-07-28 14:31:30.315\u001b[0m | \u001b[34m\u001b[1mDEBUG   \u001b[0m | \u001b[36muptrain.framework.base\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m123\u001b[0m - \u001b[34m\u001b[1mExecuting node: operator_0 for operator DAG: empty_response_validation\u001b[0m\n",
      "\u001b[32m2023-07-28 14:31:30.330\u001b[0m | \u001b[32m\u001b[1mSUCCESS \u001b[0m | \u001b[36muptrain.validation_wrapper.validation_manager\u001b[0m:\u001b[36mrun\u001b[0m:\u001b[36m37\u001b[0m - \u001b[32m\u001b[1mValidation check PASSED after 1 attempt(s)\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for inputs in dataset.to_dicts()[:20]:\n",
    "    validated_response = validation_manager.run(inputs)\n",
    "    print(\"\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
