{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "27865390-6175-4748-b877-8b9e8a6ebd6f",
   "metadata": {},
   "source": [
    "<h1 align=\"center\">\n",
    "  <a href=\"https://uptrain.ai\">\n",
    "    <img width=\"300\" src=\"https://user-images.githubusercontent.com/108270398/214240695-4f958b76-c993-4ddd-8de6-8668f4d0da84.png\" alt=\"uptrain\">\n",
    "  </a>\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828785b7-7b94-41cb-99e4-097312876118",
   "metadata": {},
   "source": [
    "<h1 style=\"text-align: center;\">Drift Detection: Text Summarization</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9362701a-3cac-4a81-8eec-189603fc00e3",
   "metadata": {},
   "source": [
    "**Overview**: In this example, we will see how to use UpTrain to monitor performance of a text summarization task in NLP. Summarization creates a shorter version of a document or an article that captures all the important information. For the same, we will be using a pretrained [text summarization model](https://huggingface.co/t5-small) (with T5 architecture) from [Huggingface](https://huggingface.co/docs/transformers/tasks/summarization). This model was trained on the [billsum dataset](https://huggingface.co/datasets/billsum).\n",
    "\n",
    "**Why is monitoring needed**: Monitoring NLP tasks with traditional metrics (such as accuracy) in production is hard, as groud truth is unavailable (or extremely delayed when there is a human in the loop). And, hence, it becomes very important to develop techniques to monitor real time monitoring for tasks such as text summarization before important business metrics (such as customer satisfaction and revenue) are affected.\n",
    "\n",
    "**Problem**: In this example, the model was trained on the [billsum dataset](https://huggingface.co/datasets/billsum). This dataset contains the articles and their summarization of the US Congressional and California state bills. However, in production, we append some samples from the [wikihow dataset](https://github.com/mahnazkoupaee/WikiHow-Dataset). The WikiHow is a large-scale dataset using the online [WikiHow](http://www.wikihow.com/) knowledge base. As you can imagine, the two datasets are quite different. It would be interesting to see how the text summarization task performs in production ðŸ¤”\n",
    "\n",
    "**Solution**: We will be using UpTrain framework which provides an easy-to-configure way to log  training data, production data and model's predictions. We apply several techniques on theis logged data, such as clustering, data drift detection and customized signals, to monitor performance and raise alerts in case of any dip in model's performance ðŸš€"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb847e5-4466-4996-a6d5-2ccb371e7a54",
   "metadata": {},
   "source": [
    "### Install Required packages\n",
    "- [PyTorch](https://pytorch.org/get-started/locally/): Deep learning framework.\n",
    "- [Hugging Face Transformers](https://huggingface.co/docs/transformers/installation): To use pretrained state-of-the-art models.\n",
    "- [Hugging Face Datasets](https://pypi.org/project/datasets/): Use public Hugging Face datasets\n",
    "- [NLTK](https://www.nltk.org/install.html): Use NLTK for sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "420d7403-4368-400d-af13-55abfb1c9848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install uptrain torch transformers nltk datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb821711-dfe5-4d29-b175-aab24dd29aa6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/vipul/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "from datasets import load_dataset\n",
    "import uptrain\n",
    "import json\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import time\n",
    "\n",
    "from helper_funcs import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765fc166-5489-431f-931a-a37bd09cc972",
   "metadata": {},
   "source": [
    "## Step 1: Setup - Defining model and datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb6841c-91e3-4be4-9c9b-0de74526a2e0",
   "metadata": {},
   "source": [
    "### Define model and tokenizer for the summarization task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13c29040-506e-4e17-9e2b-4d8b7e112e06",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer_t5 = AutoTokenizer.from_pretrained(\"t5-small\")\n",
    "model_t5 = AutoModelForSeq2SeqLM.from_pretrained(\"t5-small\")\n",
    "prefix = \"summarize: \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af26b680-b9dc-4445-a7ab-726f36768a45",
   "metadata": {},
   "source": [
    "### Load Billsum dataset from Huggingface which was used to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8394178a-d025-4ccb-b7f7-6529b77768e5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default\n",
      "Found cached dataset billsum (/Users/vipul/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc)\n",
      "Loading cached processed dataset at /Users/vipul/.cache/huggingface/datasets/billsum/default/3.0.0/75cf1719d38d6553aa0e0714c393c74579b083ae6e164b2543684e3e92e0c4cc/cache-10b05b1614ccfdc2.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'summary', 'title'],\n",
       "        num_rows: 989\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'summary', 'title'],\n",
       "        num_rows: 248\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "billsum_dataset = load_dataset(\"billsum\", split=\"ca_test\").filter(lambda x: x['text'] is not None)\n",
    "billsum = billsum_dataset.train_test_split(test_size=0.2)\n",
    "billsum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e8e4b8-46d2-4613-a21f-74f2489b2b4c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Download the wikihow dataset\n",
    "Create a small test dataset from the [Wikihow](https://github.com/mahnazkoupaee/WikiHow-Dataset) dataset to test our summarization model. Download the wikihow dataset from https://ucsb.app.box.com/s/ap23l8gafpezf4tq3wapr6u8241zz358 and save it as 'wikihowAll.csv' in the current directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed2a40f5-551c-4a85-83b6-2a51aec584d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wikihow_rand1k.csv already present\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-7c98af382f68baf2\n",
      "Found cached dataset csv (/Users/vipul/.cache/huggingface/datasets/csv/default-7c98af382f68baf2/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd21f66eea2040f3aae0d603c2d10c7b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /Users/vipul/.cache/huggingface/datasets/csv/default-7c98af382f68baf2/0.0.0/652c3096f041ee27b04d2232d41f10547a8fecda3e284a79a0ec4053c916ef7a/cache-8e6cf9a919adbb04.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['Unnamed: 0', 'summary', 'title', 'text'],\n",
       "        num_rows: 540\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['Unnamed: 0', 'summary', 'title', 'text'],\n",
       "        num_rows: 453\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "download_wikihow_csv_file('wikihow_rand1k.csv')\n",
    "wikihow_dataset = load_dataset(\"csv\", data_files='wikihow_rand1k.csv').filter(lambda x: x['text'] is not None)\n",
    "wikihow_dataset = wikihow_dataset.rename_column(\"headline\", \"summary\")\n",
    "wikihow = wikihow_dataset['train'].train_test_split(test_size=453)\n",
    "wikihow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "018c3a5d-d251-4eba-b797-477b3618768e",
   "metadata": {},
   "source": [
    "### Create a test dataset by combining billsum and wikihow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef52f3d3-d866-4b4d-b3a9-d7bb353e2c07",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c01b398b3f45455a8c5dc4e8d17dc5c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Flattening the indices:   0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text', 'summary', 'title', 'Unnamed: 0', 'dataset_label'],\n",
       "    num_rows: 701\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_test_dataset = combine_datasets(billsum[\"test\"], 'billsum_test', wikihow['test'], 'wikihow_test')\n",
    "final_test_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f468bb3-fd0c-4fc9-860e-1ab5e17f5671",
   "metadata": {},
   "source": [
    "### Let's try out our model on one of the sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d363ff6f-2a3f-418b-ba4d-6f0635435418",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e58ae693a114128a4be4b5f5f9d6170",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model_input_text_to_summarize': \" Chickens do wander just like an outside cat. The last thing you want is the chickens walking across the road or ending up in the neighbours garden. Set up fencing or chicken wire for your flock to be sure that they are safe. It also keeps predators out.\\n\\n, Some plants can be toxic to chickens just like some types of foods. You can find a list by researching online. If you know what types of plants you have in your garden give them a search online.\\n\\n\\nAlthough chickens will avoid plants that are dangerous to them, there are always exceptions with them.\\n\\n, These are bad for chickens as they like to graze on grass often. If the chickens ingest these chemicals it can make them possibly ill.\\n\\n, All the foraging around the garden can be bad on the crop if you don't maintain the chickens well. Grit helps the chickens digest the nutrition they come across.\\n\\n\"} \n",
      "\n",
      "{'model_output_summary': ['chickens wander just like an outside cat. set up fencing or chicken wire for your flock']}\n"
     ]
    }
   ],
   "source": [
    "sample_text = final_test_dataset.filter(lambda x: len(x[\"text\"]) < 1000)['text'][0]\n",
    "input_embs = tokenizer_t5(prefix + sample_text, truncation=True, padding=True, return_tensors=\"pt\").input_ids\n",
    "summary = tokenizer_t5.batch_decode(model_t5.generate(input_embs), skip_special_tokens=True)\n",
    "print({\"model_input_text_to_summarize\": sample_text}, \"\\n\")\n",
    "print({\"model_output_summary\": summary})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b435be75-f12a-4858-86d4-8ba47d52de16",
   "metadata": {},
   "source": [
    "## Using embeddings for model monitoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c297c5-acca-456a-9d84-ed58be87b437",
   "metadata": {},
   "source": [
    "To compare the two datasets, we will be utilizing text embeddings (generated by BERT). As we will see below, we can see clear differentiations between the two datasets in the embeddings space which could be an important metric to track drifts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4114d45-b745-4228-94e6-9f5174229cc9",
   "metadata": {},
   "source": [
    "#### Save bert embeddings for the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eeba6860-e5ab-4e2d-9f22-f70723b158cf",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings for reference dataset exists. Skipping generating again.\n"
     ]
    }
   ],
   "source": [
    "# Generate BERT embeddings for the reference (aka training) dataset\n",
    "generate_reference_dataset_with_embeddings(billsum['train'], \n",
    "                    tokenizer_t5, model_t5, dataset_label=\"billsum_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e7264b1-a9a3-4620-9376-64b2e83229ad",
   "metadata": {},
   "source": [
    "## Step 2: Visualizing embeddings using UpTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbad504c-40e9-4425-ace7-62a4191b7be0",
   "metadata": {},
   "source": [
    "Let's first visualize how does the embeddings of the training dataset compares against that of our real-world testing dataset. We use two dimensionality reduction techniques, UMAP and t-SNE, for embedding visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "846c6e4d-4c28-4f9c-ae08-ed8502a7f2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_check = {\n",
    "    'type': uptrain.Visual.UMAP,\n",
    "    \"measurable_args\": {\n",
    "        'type': uptrain.MeasurableType.INPUT_FEATURE,\n",
    "        'feature_name': 'bert_embs'\n",
    "    },\n",
    "    \"label_args\": {\n",
    "        'type': uptrain.MeasurableType.INPUT_FEATURE,\n",
    "        'feature_name': 'dataset_label'\n",
    "    },\n",
    "    \"hover_args\": [{\n",
    "        'type': uptrain.MeasurableType.PREDICTION,\n",
    "        'feature_name': 'output'\n",
    "    }],\n",
    "    'min_dist': 0.01,\n",
    "    'n_neighbors': 20,\n",
    "    'metric_umap': 'euclidean',\n",
    "    'dim': '2D',\n",
    "    \"update_freq\": 100,\n",
    "    'initial_dataset': \"ref_dataset.json\",\n",
    "    \"do_clustering\": False,\n",
    "    'feature_args': [{\n",
    "        'type': uptrain.MeasurableType.CUSTOM,\n",
    "        'signal_formulae': uptrain.Signal('Num_words', get_num_words_in_text),\n",
    "        'feature_name': \"Num_words\",\n",
    "        'allowed_values': ['0-200', '200-500', '500-750', '750-1000', '1000-2000', '2000-5000', '5000-100000']\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00c3bd4c-14bd-4e68-9f86-1ef69113ef9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_check = {\n",
    "    'type': uptrain.Visual.TSNE,\n",
    "    \"measurable_args\": {\n",
    "        'type': uptrain.MeasurableType.INPUT_FEATURE,\n",
    "        'feature_name': 'bert_embs'\n",
    "    },\n",
    "    \"label_args\": {\n",
    "        'type': uptrain.MeasurableType.INPUT_FEATURE,\n",
    "        'feature_name': 'dataset_label'\n",
    "    },\n",
    "    \"hover_args\": [{\n",
    "        'type': uptrain.MeasurableType.PREDICTION,\n",
    "        'feature_name': 'output'\n",
    "    }],\n",
    "    'dim': '2D',\n",
    "    \"update_freq\": 100,\n",
    "    'initial_dataset': \"ref_dataset.json\",\n",
    "    \"do_clustering\": False,\n",
    "    'feature_args': [{\n",
    "        'type': uptrain.MeasurableType.CUSTOM,\n",
    "        'signal_formulae': uptrain.Signal('Num_words', get_num_words_in_text),\n",
    "        'feature_name': \"Num_words\",\n",
    "        'allowed_values': ['0-200', '200-500', '500-750', '750-1000', '1000-2000', '2000-5000', '5000-100000']\n",
    "    }]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e1c95a7-c63e-4a7f-be87-a283fde77089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"checks\": [umap_check, tsne_check],\n",
    "    \"logging_args\": {\"st_logging\": True},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "228663de-8e5e-4471-8287-22d42badecd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data\n",
      "Deleting the folder:  uptrain_logs\n",
      "\n",
      "  You can now view your Streamlit app in your browser.\n",
      "\n",
      "  Local URL: http://localhost:8501\n",
      "  Network URL: http://192.168.6.64:8501\n",
      "\n",
      "Num predictions logged: 100\n",
      "Num predictions logged: 200\n",
      "Num predictions logged: 300\n",
      "Num predictions logged: 400\n",
      "Num predictions logged: 500\n",
      "Num predictions logged: 600\n",
      "Num predictions logged: 700\n"
     ]
    }
   ],
   "source": [
    "framework_umap = uptrain.Framework(cfg_dict=config)\n",
    "\n",
    "batch_size = 100\n",
    "all_summaries = []\n",
    "all_bert_embs = []\n",
    "\n",
    "for idx in range(int(len(final_test_dataset)/batch_size)):\n",
    "    this_batch = [prefix + doc for doc in final_test_dataset[idx*batch_size: (idx+1)*batch_size]['text']]\n",
    "\n",
    "    # Text encoder\n",
    "    input_embs = tokenizer_t5(this_batch, truncation=True, padding=True, return_tensors=\"pt\").input_ids\n",
    "    \n",
    "    # Getting output values\n",
    "    output_embs = model_t5.generate(input_embs)\n",
    "    \n",
    "    # Text decoder\n",
    "    summaries = tokenizer_t5.batch_decode(output_embs, skip_special_tokens=True)\n",
    "    all_summaries.append(summaries)\n",
    "\n",
    "    bert_embs = convert_sentence_to_emb(summaries)\n",
    "    all_bert_embs.append(bert_embs)\n",
    "\n",
    "    inputs = {\n",
    "        \"text\": this_batch,\n",
    "        \"bert_embs\": bert_embs,\n",
    "        \"dataset_label\": final_test_dataset[idx*batch_size: (idx+1)*batch_size]['dataset_label']\n",
    "    }\n",
    "\n",
    "    idens = framework_umap.log(inputs=inputs, outputs=summaries)\n",
    "    print(\"Num predictions logged:\", (idx+1)*batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a9ddb22-20e5-42a0-a253-8a916cd8d469",
   "metadata": {},
   "source": [
    "### UpTrain package includes two types of dimensionality reduction techniques: U-MAP and t-SNE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981a0637-1e8a-42cd-9989-3208b0b18b80",
   "metadata": {},
   "source": [
    "As we can clearly see, samples from the wikihow dataset form a different cluster compared to that of the training clusters from the billsum datasets. UpTrain gives a real-time dashboard of the embeddings of the inputs/outputs of your language models, helping you visualize these drifts before they start impacting your models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a88aff-f6e9-4d78-8608-2ac44306f062",
   "metadata": {},
   "source": [
    "#### 1. UMAP compression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edf784d-b2b8-40a9-8e93-881b68ca0ab4",
   "metadata": {},
   "source": [
    "![umap_compression.png](https://uptrain-demo.s3.us-west-1.amazonaws.com/text_summarization/umap.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3f7957-ac58-405a-9475-67fa039c77b6",
   "metadata": {},
   "source": [
    "#### 2. t-SNE dimensionality reduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcc087bf-5d9d-40a1-aed3-99fd74820739",
   "metadata": {},
   "source": [
    "<img width=\"800\" src=\"https://uptrain-demo.s3.us-west-1.amazonaws.com/text_summarization/t-SNE.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da365859-25b2-4e16-ab0b-3d9a4f56d02d",
   "metadata": {},
   "source": [
    "Play around with t-SNE and UMAP dimensionality reduction techniques in the UpTrain dashboard and see if you can find any interesting insights on how UMAP behaves vs how TSNE behaves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305432b4-930f-47f9-b562-870a68338b16",
   "metadata": {},
   "source": [
    "## Step 3: Quantifying Data Drift via embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2d4ce5f-4edb-4fb4-be85-f9e0ad90eaf8",
   "metadata": {},
   "source": [
    "Now that we see embeddings belong to different clusters, we will see how to quantify (which could enable us to add Slack or Pagerduty alerts) using the data drift anomaly defined in UpTrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46957d75-2047-4545-b8f4-b000dd33d6d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Downsampling Bert embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846e226-5e26-4d74-9928-57c494b8d8b7",
   "metadata": {},
   "source": [
    "For the sake of simplicity, we are downsampling the bert embeddings from dim-384 to 16 by average pooling across features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dc413159-f466-437e-9247-58551395cd22",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "config['checks'].append({\n",
    "    'type': uptrain.Monitor.DATA_DRIFT,\n",
    "    \"measurable_args\": {\n",
    "        'type': uptrain.MeasurableType.INPUT_FEATURE,\n",
    "        'feature_name': 'bert_embs_downsampled'\n",
    "    },\n",
    "    \"is_embedding\": True,\n",
    "    'reference_dataset': \"ref_dataset.json\",\n",
    "    \"hover_label_args\": {\n",
    "        'type': uptrain.MeasurableType.PREDICTION,\n",
    "        'feature_name': 'output'\n",
    "    },\n",
    "    \"initial_skip\": 50,\n",
    "    \"emd_threshold\": 2,\n",
    "    \"do_low_density_check\": True,\n",
    "    \"outlier_idxs\": [39, 192, 138, 183, 593, 832],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4a2d7a12-318c-4402-8216-2c3e52acdf68",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data\n",
      "Deleting the folder:  uptrain_logs\n",
      "50 edge cases identified out of 300 total samples\n",
      "Some edge cases (i.e. points which are far away from training clusters, identified by UpTrain:\n",
      "['\"a custodian may deny a request under this part from a fi\"', '\"the department of food and agriculture shall administer a medical cannabis Cultivation Program.\"', '\"a California State University campus-based mandatory fee is not reallocated. the fee\"', '\"a person owing support has the means to pay support while incarcerated or in\"', '\"the dental board of California is establishing the California Dental Corps Loan Repayment Program of 2002 \"', '\"2.3 million people are incarcerated in the united states each year. 700,\"', '\"a person exempt under this paragraph shall not otherwise engage in the practice of veterinary medicine\"', '\"a person, including any juvenile, is convicted of or pleads guilty or no\"', '\"the prepaid MTS surcharge shall be imposed as a percentage of the sales price\"', '\"a registered dental hygienist in alternative practice corporation is a professional corporation\"']\n"
     ]
    }
   ],
   "source": [
    "framework_data_drift = uptrain.Framework(cfg_dict=config)\n",
    "\n",
    "for idx in range(int(len(final_test_dataset)/batch_size)):\n",
    "    this_batch = [prefix + doc for doc in final_test_dataset[idx*batch_size: (idx+1)*batch_size]['text'] if doc is not None]\n",
    "    summaries = all_summaries[idx]\n",
    "    bert_embs = all_bert_embs[idx]\n",
    "    inputs = {\n",
    "        \"text\": this_batch,\n",
    "        \"bert_embs\": bert_embs,\n",
    "        \"bert_embs_downsampled\": downsample_embs(bert_embs),\n",
    "        \"dataset_label\": final_test_dataset[idx*batch_size: (idx+1)*batch_size]['dataset_label']\n",
    "    }\n",
    "    \n",
    "    idens = framework_data_drift.log(inputs=inputs, outputs=summaries)\n",
    "    time.sleep(1)\n",
    "\n",
    "collected_edge_cases = pd.read_csv(os.path.join(\"uptrain_smart_data\", \"1\", \"smart_data.csv\"))\n",
    "print(\"Some edge cases (i.e. points which are far away from training clusters, identified by UpTrain:\")\n",
    "print(collected_edge_cases['output'].tolist()[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d81aeeca-0b71-4221-acfb-5b4b3335ef08",
   "metadata": {},
   "source": [
    "UpTrain over-clusters the reference dataset, assigns cluster to the real-world data-points based on nearest distance and compares the two distributions using earth moving costs. As seen from below, the cluster assignment for the production dataset is significantly different from the reference dataset -> we are observing a significant drift in our data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12cd1e-2925-438a-8a36-9d5060195319",
   "metadata": {},
   "source": [
    "<img width=\"700\" src=\"https://uptrain-demo.s3.us-west-1.amazonaws.com/text_summarization/bar_graph.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff9e1cd4-e589-4dbb-88b5-bc42cf730461",
   "metadata": {},
   "source": [
    "Now that we can visually make sense of the drift, UpTrain also provides a quantitative measure (Earth moving distance between the production and reference distribution) which can be used to alert whenever a significant drift is observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fd3cdf-1a7d-4096-80f1-0d42333def28",
   "metadata": {},
   "source": [
    "<img width=\"700\" src=\"https://uptrain-demo.s3.us-west-1.amazonaws.com/text_summarization/line_plot_emd.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c867bfe-4b1e-4e26-b0ee-d071021537c3",
   "metadata": {},
   "source": [
    "In addition to embeddings, UpTrain allows you to monitor drifts across any custom measure which one might care about. For example, in this case, we can monitor drift on metrics such as text language, user emotion, intent, occurence of a certain keyword, text topic, etc. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04393c8d-4b58-4a48-9c87-4cdb0544cdbc",
   "metadata": {},
   "source": [
    "## Step 4: Identifying edge cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c2bd3b1-15dc-4b13-b7ed-1a379120ec11",
   "metadata": {},
   "source": [
    "Now, that we have identified issues with our models, let's also see how can we use UpTrain to identify model failure cases. Since for out-of-distribution samples, we expect the model outputs to be wrong, we can define rules which can help us catch those failure cases. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77869d7b-8124-4a1c-a995-4adbecce769a",
   "metadata": {},
   "source": [
    "We will define two rules - Output is grammatically incorrect, and the sentiment of the output is negative (we don't expect negative setiment outputs on the wikihow dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08fa23af-71c0-432b-af3d-1f01e4584044",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def grammar_check_func(inputs, outputs, gts=None, extra_args={}):\n",
    "    is_incorrect = []\n",
    "    for output in outputs:\n",
    "        if output[-1] == \"'\":\n",
    "            output = output[0:-1]\n",
    "        output = output.lower()\n",
    "        this_incorrect = False\n",
    "        if \",,,\" in output:\n",
    "            this_incorrect = True\n",
    "        if output[-3:-1] == 'the':\n",
    "            this_incorrect = True\n",
    "        if output[-2:-1] in ['an', 'if']:\n",
    "            this_incorrect = True\n",
    "        is_incorrect.append(this_incorrect)\n",
    "    return is_incorrect\n",
    "\n",
    "\n",
    "def negative_sentiment_score_func(inputs, outputs, gts=None, extra_args={}):\n",
    "    scores = []\n",
    "    for input in inputs[\"text\"]:\n",
    "        txt = input.lower()\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        scores.append(sia.polarity_scores(txt)['neg'])\n",
    "    return scores\n",
    "\n",
    "config['checks'].append({\n",
    "    'type': uptrain.Monitor.EDGE_CASE,\n",
    "    'signal_formulae': uptrain.Signal(\"Incorrect Grammer\", grammar_check_func) \n",
    "        | (uptrain.Signal(\"Sentiment Score\", negative_sentiment_score_func) > 0.5)\n",
    "})\n",
    "\n",
    "config['checks'].append({\n",
    "    'type': uptrain.Monitor.DATA_INTEGRITY,\n",
    "    \"measurable_args\": {\n",
    "        'type': uptrain.MeasurableType.CUSTOM,\n",
    "        'signal_formulae': uptrain.Signal('Num propositions', get_num_prepositions_in_text, \n",
    "                                extra_args={'buckets': [0, 200, 500, 750, 1000, 2000, 5000, 100000, 100000000]})\n",
    "    },\n",
    "    'integrity_type': 'greater_than',\n",
    "    'threshold': 7,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "58c98b91-3d18-4a6a-be2b-c3fb716221f0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting the folder:  uptrain_smart_data\n",
      "Deleting the folder:  uptrain_logs\n",
      "55 edge cases identified out of 300 total samples\n",
      "Some collected edge cases\n",
      "['\"a custodian may deny a request under this part from a fi\"', '\"the department of food and agriculture shall administer a medical cannabis Cultivation Program.\"', '\"a California State University campus-based mandatory fee is not reallocated. the fee\"', '\"a person owing support has the means to pay support while incarcerated or in\"', '\"the dental board of California is establishing the California Dental Corps Loan Repayment Program of 2002 \"', '\"2.3 million people are incarcerated in the united states each year. 700,\"', '\"a person exempt under this paragraph shall not otherwise engage in the practice of veterinary medicine\"', '\"a person, including any juvenile, is convicted of or pleads guilty or no\"', '\"the prepaid MTS surcharge shall be imposed as a percentage of the sales price\"', '\"a registered dental hygienist in alternative practice corporation is a professional corporation\"']\n"
     ]
    }
   ],
   "source": [
    "framework_edge_cases = uptrain.Framework(cfg_dict=config)\n",
    "\n",
    "for idx in range(int(len(final_test_dataset)/batch_size)):\n",
    "    this_batch = [prefix + doc for doc in final_test_dataset[idx*batch_size: \n",
    "                                (idx+1)*batch_size]['text'] if doc is not None]\n",
    "    summaries = all_summaries[idx]\n",
    "    bert_embs = all_bert_embs[idx]\n",
    "    inputs = {\n",
    "        \"text\": this_batch,\n",
    "        \"bert_embs\": bert_embs,\n",
    "        \"bert_embs_downsampled\": downsample_embs(bert_embs),\n",
    "        \"dataset_label\": final_test_dataset[idx*batch_size: (idx+1)*batch_size]['dataset_label']\n",
    "    }\n",
    "\n",
    "    idens = framework_edge_cases.log(inputs=inputs, outputs=summaries)\n",
    "\n",
    "collected_edge_cases = pd.read_csv(os.path.join(\"uptrain_smart_data\", \"1\", \"smart_data.csv\"))\n",
    "print(\"Some collected edge cases\")\n",
    "print(collected_edge_cases['output'].tolist()[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0066276-75f3-45b4-beb5-29965f1e300a",
   "metadata": {},
   "source": [
    "In this example, we saw how to identify distribution shifts in Natural language related tasks by taking advantage of text embeddings "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
