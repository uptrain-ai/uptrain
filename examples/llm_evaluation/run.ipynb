{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3fe33bf-524c-4498-a075-d0cc804947f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install uptrain rouge datasets umap-learn matplotlib py7zr torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c04ef1f-5048-4587-bbc0-da13ebafb0a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch is available but CUDA is not. Defaulting to SciPy for SVD\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import uptrain\n",
    "from rouge import Rouge \n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import subprocess\n",
    "import zipfile\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSeq2SeqLM\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81ce1cfe-a53f-4212-9c05-5fb3144faa28",
   "metadata": {},
   "source": [
    "#### Following functions are for testing purposes only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba812c4c-1a00-4047-8326-77217255ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[\n",
    "        0\n",
    "    ]  # First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(\n",
    "        input_mask_expanded.sum(1), min=1e-9\n",
    "    )\n",
    "\n",
    "\n",
    "# Function to get bert embeddings from sentences list\n",
    "def convert_sentence_to_emb(sentences, sentence_emb_model, device):\n",
    "    # Load model from HuggingFace Hub\n",
    "    tokenizer = AutoTokenizer.from_pretrained(sentence_emb_model)\n",
    "    model = AutoModel.from_pretrained(sentence_emb_model).to(device)\n",
    "\n",
    "    # Tokenize sentences\n",
    "    encoded_input = tokenizer(\n",
    "        sentences, padding=True, truncation=True, return_tensors=\"pt\"\n",
    "    ).to(device)\n",
    "\n",
    "    # Compute token embeddings\n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "\n",
    "    # Perform pooling\n",
    "    embs = mean_pooling(model_output, encoded_input[\"attention_mask\"])\n",
    "\n",
    "    # Normalize embeddings\n",
    "    return np.array(F.normalize(embs, p=2, dim=1).cpu())\n",
    "\n",
    "\n",
    "def get_summary_and_embs(tokenizer, model, text, device, max_new_tokens=30):\n",
    "    prefix = \"summarize: \"\n",
    "    this_batch = [prefix + doc for doc in text if doc is not None]\n",
    "    # Text encoder\n",
    "    input_embs = tokenizer(\n",
    "        this_batch, truncation=True, padding=True, return_tensors=\"pt\"\n",
    "    ).input_ids.to(device)\n",
    "\n",
    "    # Getting output values\n",
    "    output_embs = model.generate(input_embs, max_new_tokens=max_new_tokens)\n",
    "\n",
    "    # Text decoder\n",
    "    summaries = tokenizer.batch_decode(output_embs, skip_special_tokens=True)\n",
    "    bert_embs = convert_sentence_to_emb(summaries, sentence_emb_model, device)\n",
    "    return summaries, output_embs.cpu().numpy(), bert_embs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdff5085-21b8-4292-99bd-2cbcef5ecf84",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:datasets.builder:Found cached dataset samsum (/Users/vipul/.cache/huggingface/datasets/samsum/samsum/0.0.0/f1d7c6b7353e6de335d444e424dc002ef70d1277109031327bc9cc6af5d3d46e)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9e6038035bd454ab4cbb2010354fbd3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "samsum_dataset = load_dataset(\"samsum\")\n",
    "golden_dataset = samsum_dataset[\"test\"][0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d1cfcb85-7a57-4b4f-8f2b-5cbfae0ff847",
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "else:\n",
    "    device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4f5f25b6-d7a5-4b5f-bca2-a66eb6686b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_model = \"yasminesarraj/flan-t5-small-samsum\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f128f66-8798-4204-ba0c-791aa285d0f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_emb_model = \"sentence-transformers/paraphrase-MiniLM-L6-v2\"\n",
    "# sentence_emb_model = \"sentence-transformers/all-MiniLM-L6-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "961f9590-12ad-48d6-9b28-3387c3ef3ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# summaries, output_embs, bert_embs = get_summary_and_embs(tokenizer, model, golden_dataset['dialogue'], device, max_new_tokens=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c940e7f7-f51a-467a-89d8-c3fd5d5b0f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    \"checks\": [{\n",
    "        'type': uptrain.Monitor.LLM_EVALUATION,\n",
    "        \"measurable_args\": {\n",
    "            \"type\": uptrain.MeasurableType.INPUT_FEATURE,\n",
    "            \"feature_name\": \"dialogues\"\n",
    "        },\n",
    "        \"embedding_model\": sentence_emb_model,\n",
    "        \"llm_model_args\": {\"model_name\": summary_model},\n",
    "        \"distance_types\": [\"cosine_distance\", \"l2_distance\"],\n",
    "    }],\n",
    "    \"logging_args\": {\n",
    "        \"st_logging\": True,\n",
    "        \"use_new_handler\": True,\n",
    "        \"run_background_streamlit\": False\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ed84ba3d-f325-4ce3-91e2-d24e9c1391eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deleting contents of the folder:  uptrain_smart_data\n",
      "Deleting contents of the log folder at: uptrain_logs\n",
      "To start the streamlit dashboard, run the following command:  streamlit run /Users/vipul/Downloads/uptrain_repos/uptrain/uptrain/core/classes/logging/new_st_run.py  -- uptrain_logs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " 4,\n",
       " 5,\n",
       " 6,\n",
       " 7,\n",
       " 8,\n",
       " 9,\n",
       " 10,\n",
       " 11,\n",
       " 12,\n",
       " 13,\n",
       " 14,\n",
       " 15,\n",
       " 16,\n",
       " 17,\n",
       " 18,\n",
       " 19,\n",
       " 20,\n",
       " 21,\n",
       " 22,\n",
       " 23,\n",
       " 24,\n",
       " 25,\n",
       " 26,\n",
       " 27,\n",
       " 28,\n",
       " 29,\n",
       " 30,\n",
       " 31,\n",
       " 32,\n",
       " 33,\n",
       " 34,\n",
       " 35,\n",
       " 36,\n",
       " 37,\n",
       " 38,\n",
       " 39,\n",
       " 40,\n",
       " 41,\n",
       " 42,\n",
       " 43,\n",
       " 44,\n",
       " 45,\n",
       " 46,\n",
       " 47,\n",
       " 48,\n",
       " 49,\n",
       " 50,\n",
       " 51,\n",
       " 52,\n",
       " 53,\n",
       " 54,\n",
       " 55,\n",
       " 56,\n",
       " 57,\n",
       " 58,\n",
       " 59,\n",
       " 60,\n",
       " 61,\n",
       " 62,\n",
       " 63,\n",
       " 64,\n",
       " 65,\n",
       " 66,\n",
       " 67,\n",
       " 68,\n",
       " 69,\n",
       " 70,\n",
       " 71,\n",
       " 72,\n",
       " 73,\n",
       " 74,\n",
       " 75,\n",
       " 76,\n",
       " 77,\n",
       " 78,\n",
       " 79,\n",
       " 80,\n",
       " 81,\n",
       " 82,\n",
       " 83,\n",
       " 84,\n",
       " 85,\n",
       " 86,\n",
       " 87,\n",
       " 88,\n",
       " 89,\n",
       " 90,\n",
       " 91,\n",
       " 92,\n",
       " 93,\n",
       " 94,\n",
       " 95,\n",
       " 96,\n",
       " 97,\n",
       " 98,\n",
       " 99]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "framework = uptrain.Framework(cfg_dict=cfg)\n",
    "ids = framework.log(inputs={\"dialogues\": golden_dataset['dialogue']}, outputs=None)\n",
    "framework.log(identifiers=ids, gts=golden_dataset[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c02466b-98e7-4149-a54d-49a9cbd06725",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
