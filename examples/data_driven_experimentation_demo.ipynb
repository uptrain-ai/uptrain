{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f9mswTdkXAbM"
   },
   "source": [
    "# Data-driven experimentation via UpTrain Evaluations\n",
    "Welcome to this comprehensive guide on evaluating LLM applications and experimenting with different retrieval configurations with UpTrain. This guide aims to provide a seamless experience, offering step-by-step instructions, code explanations, and best practices.\n",
    "\n",
    "## Overview\n",
    "UpTrain is an open-source LLM evaluation tool. It provides pre-built metrics to check LLM responses on aspects such as correctness, hallucination, toxicity, etc. as well as provides an easy-to-use framework to configure custom checks.\n",
    "\n",
    "## What You'll Learn\n",
    "- Setting up your environment with the necessary packages and credentials.\n",
    "- Creating a simple RAG-based application using VectorDB, OpenAI, and Langchain.\n",
    "- Leveraging the power of UpTrain to evaluate the quality of our application.\n",
    "- Experimenting with different chunking strategies and quantifying the results.\n",
    "- Utilizing UpTrain's framework for data-driven experimentation and refinement.\n",
    "\n",
    "## Prerequisites\n",
    "- Basic knowledge of Python programming.\n",
    "- An UpTrain account.\n",
    "\n",
    "Let's dive in and start building!\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgWYZiP0WEqN"
   },
   "source": [
    "**Setting up the environment**: Before we begin, it's essential to ensure all the necessary packages are installed. Run the cell below to install the required libraries for our project. This will install uptrain, openai, langchain, and faiss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FcV4SNejTueB",
    "outputId": "0e974723-d345-41dd-e072-a8e76d403d62",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: uptrain in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (0.3.4)\n",
      "Requirement already satisfied: tqdm>=4.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (4.65.0)\n",
      "Requirement already satisfied: pydantic<1.10.10 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (1.10.7)\n",
      "Requirement already satisfied: aiolimiter>=1.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (1.1.0)\n",
      "Requirement already satisfied: loguru in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/loguru-0.7.0-py3.11.egg (from uptrain) (0.7.0)\n",
      "Requirement already satisfied: lazy-loader in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (0.2)\n",
      "Requirement already satisfied: networkx in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (2.8.4)\n",
      "Requirement already satisfied: polars>=0.18 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (0.18.4)\n",
      "Requirement already satisfied: deltalake>=0.9 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.23.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (1.24.3)\n",
      "Requirement already satisfied: pyarrow>=10.0.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (10.0.1)\n",
      "Requirement already satisfied: plotly>=5.0.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/plotly-5.14.1-py3.11.egg (from uptrain) (5.14.1)\n",
      "Requirement already satisfied: streamlit>=1.23 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (1.24.0)\n",
      "Requirement already satisfied: httpx>=0.24.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from uptrain) (0.25.0)\n",
      "Requirement already satisfied: certifi in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from httpx>=0.24.1->uptrain) (2023.7.22)\n",
      "Requirement already satisfied: httpcore<0.19.0,>=0.18.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from httpx>=0.24.1->uptrain) (0.18.0)\n",
      "Requirement already satisfied: idna in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from httpx>=0.24.1->uptrain) (3.4)\n",
      "Requirement already satisfied: sniffio in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from httpx>=0.24.1->uptrain) (1.3.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/tenacity-8.2.2-py3.11.egg (from plotly>=5.0.0->uptrain) (8.2.2)\n",
      "Requirement already satisfied: packaging in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from plotly>=5.0.0->uptrain) (23.1)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from pydantic<1.10.10->uptrain) (4.5.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/altair-4.2.2-py3.11.egg (from streamlit>=1.23->uptrain) (4.2.2)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/blinker-1.6.2-py3.11.egg (from streamlit>=1.23->uptrain) (1.6.2)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/cachetools-5.3.0-py3.11.egg (from streamlit>=1.23->uptrain) (5.3.0)\n",
      "Requirement already satisfied: click<9,>=7.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from streamlit>=1.23->uptrain) (8.1.3)\n",
      "Requirement already satisfied: importlib-metadata<7,>=1.4 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from streamlit>=1.23->uptrain) (6.8.0)\n",
      "Requirement already satisfied: pandas<3,>=0.25 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from streamlit>=1.23->uptrain) (1.5.3)\n",
      "Requirement already satisfied: pillow<10,>=6.2.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from streamlit>=1.23->uptrain) (9.5.0)\n",
      "Requirement already satisfied: protobuf<5,>=3.20 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from streamlit>=1.23->uptrain) (4.24.1)\n",
      "Requirement already satisfied: pympler<2,>=0.9 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/Pympler-1.0.1-py3.11.egg (from streamlit>=1.23->uptrain) (1.0.1)\n",
      "Requirement already satisfied: python-dateutil<3,>=2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from streamlit>=1.23->uptrain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2.4 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from streamlit>=1.23->uptrain) (2.31.0)\n",
      "Requirement already satisfied: rich<14,>=10.11.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/rich-13.3.5-py3.11.egg (from streamlit>=1.23->uptrain) (13.3.5)\n",
      "Requirement already satisfied: toml<2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/toml-0.10.2-py3.11.egg (from streamlit>=1.23->uptrain) (0.10.2)\n",
      "Requirement already satisfied: tzlocal<5,>=1.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from streamlit>=1.23->uptrain) (4.3.1)\n",
      "Requirement already satisfied: validators<1,>=0.2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/validators-0.20.0-py3.11.egg (from streamlit>=1.23->uptrain) (0.20.0)\n",
      "Requirement already satisfied: gitpython!=3.1.19,<4,>=3 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/GitPython-3.1.31-py3.11.egg (from streamlit>=1.23->uptrain) (3.1.31)\n",
      "Requirement already satisfied: pydeck<1,>=0.1.dev5 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/pydeck-0.8.1b0-py3.11.egg (from streamlit>=1.23->uptrain) (0.8.1b0)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/tornado-6.3.2-py3.11-macosx-11.1-arm64.egg (from streamlit>=1.23->uptrain) (6.3.2)\n",
      "Requirement already satisfied: entrypoints in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/entrypoints-0.4-py3.11.egg (from altair<6,>=4.0->streamlit>=1.23->uptrain) (0.4)\n",
      "Requirement already satisfied: jinja2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/Jinja2-3.1.2-py3.11.egg (from altair<6,>=4.0->streamlit>=1.23->uptrain) (3.1.2)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/jsonschema-4.18.0a7-py3.11.egg (from altair<6,>=4.0->streamlit>=1.23->uptrain) (4.18.0a7)\n",
      "Requirement already satisfied: toolz in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/toolz-0.12.0-py3.11.egg (from altair<6,>=4.0->streamlit>=1.23->uptrain) (0.12.0)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/gitdb-4.0.10-py3.11.egg (from gitpython!=3.1.19,<4,>=3->streamlit>=1.23->uptrain) (4.0.10)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from httpcore<0.19.0,>=0.18.0->httpx>=0.24.1->uptrain) (3.6.2)\n",
      "Collecting h11<0.15,>=0.13\n",
      "  Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/zipp-3.15.0-py3.11.egg (from importlib-metadata<7,>=1.4->streamlit>=1.23->uptrain) (3.15.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from pandas<3,>=0.25->streamlit>=1.23->uptrain) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from python-dateutil<3,>=2->streamlit>=1.23->uptrain) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from requests<3,>=2.4->streamlit>=1.23->uptrain) (2.0.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from requests<3,>=2.4->streamlit>=1.23->uptrain) (1.26.15)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/markdown_it_py-2.2.0-py3.11.egg (from rich<14,>=10.11.0->streamlit>=1.23->uptrain) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/Pygments-2.15.1-py3.11.egg (from rich<14,>=10.11.0->streamlit>=1.23->uptrain) (2.15.1)\n",
      "Requirement already satisfied: pytz-deprecation-shim in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from tzlocal<5,>=1.1->streamlit>=1.23->uptrain) (0.1.0.post0)\n",
      "Requirement already satisfied: decorator>=3.4.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/decorator-5.1.1-py3.11.egg (from validators<1,>=0.2->streamlit>=1.23->uptrain) (5.1.1)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/smmap-5.0.0-py3.11.egg (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3->streamlit>=1.23->uptrain) (5.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/MarkupSafe-2.1.2-py3.11-macosx-11.1-arm64.egg (from jinja2->altair<6,>=4.0->streamlit>=1.23->uptrain) (2.1.2)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.23->uptrain) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/jsonschema_specifications-2023.5.1-py3.11.egg (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.23->uptrain) (2023.5.1)\n",
      "Requirement already satisfied: referencing>=0.27.2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/referencing-0.28.2-py3.11.egg (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.23->uptrain) (0.28.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/rpds_py-0.7.1-py3.11-macosx-11.1-arm64.egg (from jsonschema>=3.0->altair<6,>=4.0->streamlit>=1.23->uptrain) (0.7.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/mdurl-0.1.2-py3.11.egg (from markdown-it-py<3.0.0,>=2.2.0->rich<14,>=10.11.0->streamlit>=1.23->uptrain) (0.1.2)\n",
      "Requirement already satisfied: tzdata in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from pytz-deprecation-shim->tzlocal<5,>=1.1->streamlit>=1.23->uptrain) (2023.3)\n",
      "Installing collected packages: h11\n",
      "  Attempting uninstall: h11\n",
      "    Found existing installation: h11 0.14.0\n",
      "    Uninstalling h11-0.14.0:\n",
      "      Successfully uninstalled h11-0.14.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "uptrain-server 0.1 requires fsspec>=2023.6.0, but you have fsspec 2023.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed h11-0.14.0\n",
      "Requirement already satisfied: openai in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (0.27.7)\n",
      "Requirement already satisfied: requests>=2.20 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from openai) (2.31.0)\n",
      "Requirement already satisfied: tqdm in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from requests>=2.20->openai) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from requests>=2.20->openai) (2023.7.22)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp->openai) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: langchain in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (0.0.301)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (2.0.15)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: anyio<4.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (3.6.2)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (0.5.14)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (1.33)\n",
      "Requirement already satisfied: langsmith<0.1.0,>=0.0.38 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (0.0.40)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (1.24.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (1.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages/tenacity-8.2.2-py3.11.egg (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (2.0.4)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from anyio<4.0->langchain) (3.4)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from anyio<4.0->langchain) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.3)\n",
      "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from requests<3,>=2->langchain) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
      "Requirement already satisfied: packaging>=17.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: faiss in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (1.7.4)\n",
      "Requirement already satisfied: numpy in /Users/sourabhagrawal/miniconda3/envs/llm_eval/lib/python3.11/site-packages (from faiss) (1.24.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install uptrain\n",
    "!pip install openai\n",
    "!pip install langchain\n",
    "!pip install faiss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a95wJuh3WIoW"
   },
   "source": [
    "**Authentication**: The next step involves setting the required environment variables - mainly the openai key (for generating responses), and uptrain api key (for evaluating responses). You can create an account with UpTrain and generate the api key for free. Please visit https://uptrain.ai/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "0CIXY7rnWSvi"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"OPENAI_API_KEY\"] = \"sk-*****************\"\n",
    "UPTRAIN_API_KEY = \"up-******************\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhjfVEtLWbY4"
   },
   "source": [
    "**Importing Necessary Modules**: With the initial setup complete, let's import the essential classes and modules we'll use throughout this project. The following cell imports the required classes from langchain and Faiss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "mOrNmx-UYXNk"
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "from uptrain import APIClient, Evals\n",
    "\n",
    "from langchain.vectorstores import VectorStore\n",
    "from langchain.embeddings import OpenAIEmbeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmyJjgNeWu6G"
   },
   "source": [
    "**Loading Data from the Web**: Our application requires data to process and generate insights. In this step, we'll fetch content from a URL using the WebBaseLoader class. The loaded data will be stored in the data variable. You can replace the URL with any other source if needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "7ZD6Dk16sVzw"
   },
   "outputs": [],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://cloud.google.com/vertex-ai/docs/generative-ai/learn/generative-ai-studio\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_Yvk8JeWwxo"
   },
   "source": [
    "**Splitting the Data**: To process the data more efficiently, we'll split the loaded content into smaller chunks. The RecursiveCharacterTextSplitter class helps in achieving this by dividing the data based on specified character limits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "uwDl1n51s4ta"
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 200, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eKJtR8piWzDN"
   },
   "source": [
    "**Setting Up VectorDB with OpenAI Embeddings**: For efficient storage and retrieval of our data, we use Faiss in conjunction with OpenAI embeddings. The following cell sets up the necessary environment variables and initializes the Faiss vectorDB instance with OpenAI embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Y2rg9XHztDfz"
   },
   "outputs": [],
   "source": [
    "from langchain.vectorstores.faiss import FAISS\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "\n",
    "vectorstore = FAISS.from_documents(documents=all_splits, embedding= OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fEm4FJBYW3B4"
   },
   "source": [
    "**Setting Up the QA Prompt**: Once our data is processed and stored, we can use it to answer queries. The following cell defines a \"generate_llm_response\" which finds the document closest to the given question via vector similarity search and uses OpenAI's GPT-3.5-Turbo to generate the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bJaFpHBBtrCK",
    "outputId": "53a378fc-9b4e-4003-b908-b6a269bc0b0c"
   },
   "outputs": [],
   "source": [
    "def generate_llm_response(question, vectorstore):\n",
    "    documents = vectorstore.similarity_search(question, k= 1)\n",
    "    context = \" , \".join([x.page_content for x in documents])\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "        Answer the following user query using the retrieved document in less than 3 sentences:\n",
    "        {question}\n",
    "        The retrieved document has the following text:\n",
    "        {context}\n",
    "\n",
    "        Answer:\n",
    "    \"\"\"\n",
    "\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo\", messages=[{\"role\": \"system\", \"content\": prompt}], temperature=0.1\n",
    "    ).choices[0][\"message\"][\"content\"]\n",
    "    \n",
    "    return [{'question': question, 'context': context, 'response': response}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's try it out**: Let's try asking our QnA bot about Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'question': 'What is Vertex AI?',\n",
       "  'context': 'Generative AI on Vertex AI\\n                    \\n\\n                      Build, tune, and deploy foundation models on Vertex AI.',\n",
       "  'response': 'Vertex AI is a platform that allows users to build, tune, and deploy foundation models for generative AI.'}]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_llm_response('What is Vertex AI?', vectorstore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's define more questions**: We now define a set of questions to test our bot upon and evaluate the quality of responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"What is the primary purpose of Generative AI Studio?\",\n",
    "    'What is Responsible AI?',\n",
    "    'What is Prompt Designing?',\n",
    "    'What is Vertex AI?',\n",
    "    \"What are some of the tasks you can perform in Generative AI Studio?\",\n",
    "    'Which method is good, Prompt Designing or fine-tuning a model?',\n",
    "    'How to get good quality responses from llm?',\n",
    "    'What are some of the foundation models offered by Vertex AI?',\n",
    "    \"How can you ensure that a designed prompt elicits the desired response from a language model?\",\n",
    "    'How to use Generative AI studio to convert text to speech.',\n",
    "    \"Where can you find sample prompts to test models in Generative AI Studio?\"\n",
    "    'How can I customize the foundation models offered by vertex AI?',\n",
    "    \"What are some code examples from vertex ai?\"\n",
    "]\n",
    "\n",
    "results = []\n",
    "for question in questions:\n",
    "    results.extend(generate_llm_response(question, vectorstore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Running Experiments using UpTrain**: Let's also see how UpTrain can be used to conduct data-driven experimentation. We will increase the chunk_size from 200 to 1000 and see how that impacts the context retrieval quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate new embeddings**: We will again use faiss vectorDB to store new document embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0jBX9UZdIooX",
    "outputId": "33855f1e-8ec0-4bbe-e9ba-39f341c7844a"
   },
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size = 1000, chunk_overlap = 0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "vectorstore_new = FAISS.from_documents(documents=all_splits, embedding= OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generate responses with new vectorstore**: Let's generate new responses for the same set of questions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_larger_chunk = []\n",
    "for question in questions:\n",
    "    results_larger_chunk.extend(generate_llm_response(question, vectorstore_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Append chunk size information**: Let's add the corresponding chunk size information for both sets of results. We will pass this column name to UpTrain to compare the two experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = [x.update({\"chunk_size\": 200}) for x in results]\n",
    "_ = [x.update({\"chunk_size\": 1000}) for x in results_larger_chunk]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluating Experiments using UpTrain**: UpTrain's APIClient also provides a \"evaluate_experiments\" method which takes the input data to be evaluated along with the list of checks to be run and the name of the columns associated with the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-11-15 16:36:42.262\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36muptrain.framework.remote\u001b[0m:\u001b[36mlog_and_evaluate\u001b[0m:\u001b[36m455\u001b[0m - \u001b[1mSending evaluation request for rows 0 to <50 to the Uptrain server\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from uptrain import APIClient\n",
    "eval_client = APIClient(uptrain_api_key = UPTRAIN_API_KEY)\n",
    "\n",
    "_ = eval_client.evaluate_experiments(\n",
    "    project_name=\"VertexAI-QnA-Bot-Chunk-Size-Experiments\",\n",
    "    data=results + results_larger_chunk,\n",
    "    checks=[Evals.CONTEXT_RELEVANCE, Evals.RESPONSE_RELEVANCE, Evals.FACTUAL_ACCURACY],\n",
    "    exp_columns=['chunk_size']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Access UpTrain Dashboards**: We can access the evaluation results at https://demo.uptrain.ai/dashboard/ - the same API key can be used to access the dashboards. \n",
    "\n",
    "<img width=\"600\" src=\"https://uptrain-assets.s3.ap-south-1.amazonaws.com/images/github-assets/Screenshot+2023-11-08+at+12.10.08+AM.png\">"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
