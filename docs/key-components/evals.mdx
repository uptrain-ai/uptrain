---
title: Evals
description: Quickest way to perform evaluations on your data
---

UpTrain provides a simple and easy way to perform evaluations on your data. You can pass any of these Evals to the `log_and_evaluate` function and it will automatically perform the evaluation and log the results to the database.

These evals require a combination of the following columns to be present in your data:

- `question`: The question you want to ask
- `context`: The context relevant to the question
- `response`: The response to the question

Some evals may require additional parameters to be passed to them. These are called parametric evals. Any eval below that has a `Parameters` section is a parametric eval.

You can choose evals as per your needs. We have divided them into a few categories for your convenience.

## Response Quality

These evals are used to grade the quality of the response generated by the LLM.


### RESPONSE_RELEVANCE  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/response_quality/response_relevance.ipynb))

Grades how relevant the generated response is or if it has any additional irrelevant information for the question asked.

Columns required:
- `question`
- `response`


### RESPONSE_COMPLETENESS  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/response_quality/response_completeness.ipynb))

Grades how complete the generated response was for the question specified.

Columns required:
- `question`
- `response`


### RESPONSE_CONSISTENCY  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/response_quality/response_consistency.ipynb))

Grades how consistent the response is with the question asked as well as with the context provided.

Columns required:
- `question`
- `context`
- `response`


### RESPONSE_CONCISENESS  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/response_quality/response_conciseness.ipynb))

Grades how concise the generated response is or if it has any additional irrelevant information for the question asked.

Columns required:
- `question`
- `response`


### VALID_RESPONSE

Grades if the response generated is valid or not. A response is considered to be valid if it contains any information.

Columns required:
- `response`


### ResponseMatching

Operator to compare the llm-generated text with the gold (ideal) response using the defined score metric.

Columns required:
- `question`
- `ground_truth` - The column containing the gold responses

Paramters:
- `method` - Method to calculate the score ('rouge', 'exact' or 'llm')



## Context Awareness

These evals are used to grade how good the retrieved context is, how well the response is able to use the context, and how well the response is able to use the context to answer the question etc.

### FACTUAL_ACCURACY  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/context_awareness/factual_accuracy.ipynb))

Grades how factual the generated response was.

Columns required:
- `question`
- `context`
- `response`


### CONTEXT_RELEVANCE  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/context_awareness/context_relevance.ipynb))

Grades how relevant the context was to the question specified.

Columns required:
- `question`
- `context`


### RESPONSE_COMPLETENESS_WRT_CONTEXT  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/context_awareness/response_completeness_wrt_context.ipynb))

Grades how complete the generated response was for the question specified given the information provided in the context.

Columns required:
- `question`
- `context`
- `response`


## Language Features

These evals are used to grade the language features of the response generated by the LLM. These include fluency, politeness, grammar, coherence etc.


### CRITIQUE_LANGUAGE  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/language_features/language_critique.ipynb))

Operator to score machine generated responses in a conversation. The response is evaluated on multiple aspects - fluence, politeness, grammar, and coherence. It provides a score for each of the aspects on a scale of 0 to 1, along with an explanation for the score.

Columns required:
- `response`


### CritiqueTone  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/language_features/tone_critique.ipynb))
    
Operator to assess the tone of machine generated responses.

Columns required:
- `response`

Parameters:
- `llm_persona` - The persona the chatbot being assessed was expected to follow


### ConversationSatisfaction  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/language_features/conversation_satisfaction.ipynb))

Measures the user's satisfaction with the conversation with the LLM/AI assistant based on completeness and user's acceptance.

Columns required:
- `conversation` - The chat between the user and the LLM/AI assistant (in the form of a list of dictionaries with keys 'role' and 'content')

Parameters:
- `user_persona` - The persona of the user asking the queries
- `llm_persona` - The persona of the LLM/AI assistant


## Custom

These evals are used to grade the response generated by the LLM based on a custom metric. 


### GuidelineAdherence  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/custom/guideline_adherence.ipynb))

Grades how well the LLM adheres to a provided guideline when giving a response.

Columns required:
- `question`
- `response`

Parameters:
- `guideline` - The guideline to be followed
- `guideline_name` (optional) - User-assigned name of the guideline to distinguish between multiple checks
- `resopnse_schema` (optional) - Schema of the response in case it is of type JSON, XML, etc.


## Safeguarding

These evals are for security reasons like prevention of code injection, personal information leakage, system prompt leakage etc.


### PROMPT_INJECTION  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/safeguarding/system_prompt_injection.ipynb))

Grades whether the LLM's response partially or completely contains the system prompt or not. A higher score means that it doesn't contain the system prompt.

Columns required:
- `response`


## Code

These evals are used to grade the response generated by the LLM based on the presence of code in the response.


### CODE_IDENTIFICATION

Grades whether the LLM's response contains any code or not. A higher score means that it contains code. Also returns the code snippet if any.

Columns required:
- `response`
