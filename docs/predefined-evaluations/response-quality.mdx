---
title: Response Quality
description: Grade the quality of the response generated by the LLM.
---

### RESPONSE_RELEVANCE  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/response_quality/relevance.ipynb))

Grades how relevant the generated response is or if it has any additional irrelevant information for the question asked.

Columns required:
- `question`
- `response`


### RESPONSE_COMPLETENESS  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/response_quality/completeness.ipynb))

Grades how complete the generated response was for the question specified.

Columns required:
- `question`
- `response`


### RESPONSE_CONSISTENCY  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/response_quality/consistency.ipynb))

Grades how consistent the response is with the question asked as well as with the context provided.

Columns required:
- `question`
- `context`
- `response`


### RESPONSE_CONCISENESS  ([Tutorial](https://github.com/uptrain-ai/uptrain/blob/main/examples/checks/response_quality/conciseness.ipynb))

Grades how concise the generated response is or if it has any additional irrelevant information for the question asked.

Columns required:
- `question`
- `response`


### VALID_RESPONSE

Grades if the response generated is valid or not. A response is considered to be valid if it contains any information.

Columns required:
- `response`


### ResponseMatching

Operator to compare the llm-generated text with the gold (ideal) response using the defined score metric.

Columns required:
- `question`
- `ground_truth` - The column containing the gold responses

Paramters:
- `method` - Method to calculate the score ('rouge', 'exact' or 'llm')
