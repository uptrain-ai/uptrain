---
title: Evals
description: Quickest way to perform evaluations on your data
---

UpTrain provides a simple and easy way to perform evaluations on your data. You can pass any of these Evals to the `log_and_evaluate` function and it will automatically perform the evaluation and log the results to the database.

These evals require a combination of the following columns to be present in your data:

- `question`: The question you want to ask
- `context`: The context relevant to the question
- `response`: The response to the question

Some evals may require additional parameters to be passed to them. These are called parametric evals. Any eval below that has a `Parameters` section is a parametric eval.

You can choose evals as per your needs. We have divided them into a few categories for your convenience:

1. [Response Quality](response-quality): Grade the quality of the response generated by the LLM.
1. [Context Awareness](context-awareness): Grade how good the retrieved context is and how well the LLM is able to use it.
1. [Language Features](language-features): Grade the language features of the response generated by the LLM.
1. [Conversation](conversation): Grade the conversations between the user and the LLM/AI assistant.
1. [Safeguarding](safeguarding): Grade the security mechanisms of the LLM like prevention of code injection, personal information leakage, system prompt leakage etc.
1. [Code](code): Grade the response generated by the LLM based on the presence of code in the response.
1. [Custom](custom): Grade the performance of the LLM based on a custom metric. 